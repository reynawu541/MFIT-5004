{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MFIT 5004 GitHub.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hGZdUWpSy-E"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression as Lin_Reg\n",
        "\n",
        "from sklearn.linear_model import Ridge as Ridge_Reg\n",
        "from sklearn.linear_model import Lasso as Lasso_Reg\n",
        "from statsmodels.regression.linear_model import OLS\n",
        "import sklearn.preprocessing as Preprocessing\n",
        "\n",
        "from sklearn.linear_model import Ridge \n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import seaborn as sns\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler,PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "%matplotlib inline\n",
        "\n",
        "import itertools as it\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cmx\n",
        "import matplotlib.colors as colors\n",
        "import scipy as sp\n",
        "from itertools import combinations\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/kc_house_data.csv')"
      ],
      "metadata": {
        "id": "7uSrSPLeS4Nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "Vjd30yGtTHj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "OOv-I4bLTJgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "there are 21613 samples with 21 features initially\n",
        "\n",
        "feature description: id : A notation for a house\n",
        "\n",
        "date: Date house was sold\n",
        "\n",
        "price: Price is prediction target\n",
        "\n",
        "bedrooms: Number of bedrooms\n",
        "\n",
        "bathrooms: Number of bathrooms\n",
        "\n",
        "sqft_living: Square footage of the home\n",
        "\n",
        "sqft_lot: Square footage of the lot\n",
        "\n",
        "floors :Total floors (levels) in house\n",
        "\n",
        "waterfront :House which has a view to a waterfront\n",
        "\n",
        "view: Has been viewed\n",
        "\n",
        "condition :How good the condition is overall\n",
        "\n",
        "grade: overall grade given to the housing unit, based on King County grading system\n",
        "\n",
        "sqft_above : Square footage of house apart from basement\n",
        "\n",
        "sqft_basement: Square footage of the basement\n",
        "\n",
        "yr_built : Built Year\n",
        "\n",
        "yr_renovated : Year when house was renovated\n",
        "\n",
        "zipcode: Zip code\n",
        "\n",
        "lat: Latitude coordinate\n",
        "\n",
        "long: Longitude coordinate\n",
        "\n",
        "sqft_living15 : Living room area in 2015(implies-- some renovations) This might or might not have affected the lotsize area\n",
        "\n",
        "sqft_lot15 : LotSize area in 2015(implies-- some renovations)"
      ],
      "metadata": {
        "id": "tdLwSscUTNEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA & preprocessing"
      ],
      "metadata": {
        "id": "boWuklP2TUh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()\n",
        "# no missing value"
      ],
      "metadata": {
        "id": "CTWtozZhTK4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['floors'].value_counts().to_frame()"
      ],
      "metadata": {
        "id": "djRd_5HjTPxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(df['waterfront'], df['price'])\n",
        "plt.title(\"'Boxplot 'Waterfront' vs 'Price'\")"
      ],
      "metadata": {
        "id": "mXniHUfmTTzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.regplot(df['sqft_above'], df['price'])\n",
        "plt.title(\"Regression Plot\")\n",
        "print(\"We can see that it is positively correlated.\")"
      ],
      "metadata": {
        "id": "-vQCob6dTYxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.corr()['price'].sort_values()"
      ],
      "metadata": {
        "id": "R1dmdZmCTauh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cor = df.corr()\n",
        "plt.figure(figsize=(20,15))\n",
        "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "98Foa2dETciW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df['month'] = df['date'].apply(lambda date:date.month)\n",
        "df['year'] = df['date'].apply(lambda date:date.year)"
      ],
      "metadata": {
        "id": "41StBqffTeAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,10))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "df.groupby('month').mean()['price'].plot()\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "df.groupby('year').mean()['price'].plot()"
      ],
      "metadata": {
        "id": "56U2MnVMTfZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop('date',axis=1)\n",
        "df = df.drop('id',axis=1)"
      ],
      "metadata": {
        "id": "np0us3_vTi8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.bathrooms.unique()"
      ],
      "metadata": {
        "id": "JH7BMrVmTkfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(df.bathrooms,rwidth = 0.8)\n",
        "plt.xlabel(\"Number of bathrooms\")\n",
        "plt.ylabel(\"count\")"
      ],
      "metadata": {
        "id": "FtcdRddgTl-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(df['price'])"
      ],
      "metadata": {
        "id": "lZLo65MtTnNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# monthly change of prices\n",
        "df['ym'] = (df.index.year *100 + df.index.month).astype(str) \n",
        "ym_summary = df.groupby('ym')['price'].agg(['mean','count'])\n",
        "\n",
        "vmin = np.min(ym_summary['count'])\n",
        "vmax = np.max(ym_summary['count'])\n",
        "norm = colors.Normalize(vmin,vmax)\n",
        "\n",
        "plt.figure(figsize=(15,7))\n",
        "plt.scatter(x=np.arange(ym_summary.shape[0]), y =ym_summary['mean'],c= ym_summary['count'],\n",
        "            s= ym_summary['count'],norm=norm ,alpha = 0.8, cmap='jet')\n",
        "\n",
        "plt.plot(np.arange(ym_summary.shape[0]), ym_summary['mean'] ,'--')\n",
        "plt.xticks(np.arange(ym_summary.shape[0]),ym_summary.index.values)\n",
        "plt.yscale('log')\n",
        "plt.xlabel('Year-Month')\n",
        "plt.ylabel('Price (log scale)')\n",
        "clb = plt.colorbar() \n",
        "clb.ax.set_title('number of sales')\n",
        "plt.title('Averge Price by Month')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "35HFS283XqYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "vmin = np.min(df.price)\n",
        "vmax = np.max(df.price)\n",
        "norm = colors.LogNorm(vmin*2,vmax/3)\n",
        "plt.scatter(df.long,df.lat, marker='*',c=df.price,norm=norm,cmap='jet') \n",
        "plt.xlabel('Longitude')\n",
        "plt.ylabel('Latituede')\n",
        "plt.title('House Price by Geography')\n",
        "clb = plt.colorbar() \n",
        "clb.ax.set_title('Price')"
      ],
      "metadata": {
        "id": "U7u-yb1bX4lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scatter_p(fea,price):\n",
        "    n_f = len(fea)\n",
        "    n_row = n_f//3+1\n",
        "    fig=plt.figure(figsize=(20,15))\n",
        "    i = 1\n",
        "    for f in fea:\n",
        "        x=df[f]\n",
        "        y=df[price]\n",
        "        m, b = np.polyfit(x, y, 1)    \n",
        "        \n",
        "        ax=fig.add_subplot(n_row,3,i)\n",
        "        plt.plot(x,y,'.',color='b')\n",
        "        plt.plot(x, m*x + b, '-',color='r')\n",
        "        plt.xlabel(f)\n",
        "        plt.ylabel(price)\n",
        "        i += 1"
      ],
      "metadata": {
        "id": "2BoUYBH0X8C4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scatter_p(fea=['sqft_living', 'sqft_lot','sqft_basement'],price='price')"
      ],
      "metadata": {
        "id": "upCpEErFX-Xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['log_sqft_living'] = np.log(df['sqft_living'])\n",
        "df['log_sqft_lot'] = np.log(df['sqft_lot'])\n",
        "df['log_sqft_basement'] = np.log1p(df['sqft_basement'])\n",
        "scatter_p(fea=['log_sqft_living','log_sqft_lot','log_sqft_basement'],price='log_price')"
      ],
      "metadata": {
        "id": "MWQF-MeHYBsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['basement_ind'] = [1 if x>0 else 0 for x in df.sqft_basement]\n",
        "scatter_p(fea=['yr_built','yr_renovated','bathrooms'],price='log_price')"
      ],
      "metadata": {
        "id": "Iu2RUOf8YGpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['renovated_ind'] = [1 if x>0 else 0 for x in df.yr_renovated]\n",
        "x=df.loc[df.renovated_ind==1,'yr_renovated']\n",
        "y=df.loc[df.renovated_ind==1 ,'log_price']\n",
        "m, b = np.polyfit(x, y, 1)   \n",
        "plt.plot(x,y,'.',color='b')\n",
        "plt.plot(x, m*x + b, '-',color='r')\n",
        "plt.title('Renovated Houses')\n",
        "plt.xlabel('yr_renovated')\n",
        "plt.ylabel('log_price')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SJLFBpOFYMVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(15,12))\n",
        "fig.add_subplot(3,2,1)\n",
        "sns.violinplot(x=\"bedrooms\", y=\"log_price\", data=df)    \n",
        "fig.add_subplot(3,2,2)\n",
        "sns.violinplot(x=\"condition\", y=\"log_price\", data=df)  \n",
        "fig.add_subplot(3,2,3)\n",
        "sns.violinplot(x=\"grade\", y=\"log_price\", data=df)   \n",
        "fig.add_subplot(3,2,4)\n",
        "sns.violinplot(x=\"view\", y=\"log_price\", data=df)  \n",
        "fig.add_subplot(3,2,5)\n",
        "sns.violinplot(x=\"floors\", y=\"log_price\", data=df)  "
      ],
      "metadata": {
        "id": "gXZT_Nz_YUDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert bedrooms, floors, year_month to binary feature\n",
        "data = pd.get_dummies(df,columns=['bedrooms','floors','ym'],drop_first=True)"
      ],
      "metadata": {
        "id": "ndfkaLEJYXqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in ['price']:\n",
        "    q75,q25 = np.percentile(df.loc[:,x],[75,25])\n",
        "    intr_qr = q75-q25\n",
        " \n",
        "    max = q75+(1.5*intr_qr)\n",
        "    min = q25-(1.5*intr_qr)\n",
        " \n",
        "    df.loc[df[x] < min,x] = np.nan\n",
        "    df.loc[df[x] > max,x] = np.nan"
      ],
      "metadata": {
        "id": "8pBSqvQoTpTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "vnP1he7yTrI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# interactive map"
      ],
      "metadata": {
        "id": "Jbe8u0dEcc6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "  import folium\n",
        "  import matplotlib.cm"
      ],
      "metadata": {
        "id": "ETCimK0acecl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define color vector function\n",
        "def ColorVector(values, number_of_colors, cmap_name):\n",
        "    buckets = pd.qcut(values, number_of_colors).codes\n",
        "    cmap = matplotlib.cm.get_cmap(name = cmap_name)\n",
        "    colors = []\n",
        "    for i in range(0, number_of_colors):\n",
        "        r = int(cmap(i/number_of_colors)[0]*255)\n",
        "        g = int(cmap(i/number_of_colors)[1]*255)\n",
        "        b = int(cmap(i/number_of_colors)[2]*255)\n",
        "        color = \"#{0:02x}{1:02x}{2:02x}\".format(r, g, b)  \n",
        "        colors.append(color)\n",
        "    values = []\n",
        "    for j in range(0, len(buckets)):\n",
        "        value = colors[buckets[j]]\n",
        "        values.append(value)\n",
        "    return values\n",
        "  \n",
        "# define color categories function\n",
        "def ColorCategories(variable, colors):\n",
        "    properties['Colors'] = colors\n",
        "    counts = properties.groupby(['Colors', variable]).size().reset_index().rename(columns={0:'count'})\n",
        "    color_list = counts.Colors.unique()\n",
        "    for color in color_list:\n",
        "        temp = counts[(counts.Colors == color)]\n",
        "        print(color, min(temp[variable]), max(temp[variable]), len(temp))\n",
        "        \n",
        "# read in the data\n",
        "properties = pd.read_csv('/content/kc_house_data.csv')\n",
        "\n",
        "# prepare map components\n",
        "lats = properties['lat']\n",
        "lngs = properties['long']\n",
        "vals = properties['price']\n",
        "addresses = properties['zipcode']\n",
        "sqft = properties['sqft_living']\n",
        "# owners = properties['Owner']\n",
        "\n",
        "##### View 1 - Year Built #####\n",
        "\n",
        "#years = []\n",
        "#for year in year_built:\n",
        "#    if pd.isnull(year) == False:\n",
        "#        year = int(year)\n",
        "#    else:\n",
        "#        year = None\n",
        "#    years.append(year)\n",
        "    \n",
        "# coloring    \n",
        "#properties['YearBuilt'] = years\n",
        "years = properties['yr_built'] \n",
        "colors = ColorVector(properties['yr_built'].values, 20, 'coolwarm')\n",
        "ColorCategories('yr_built', colors)\n",
        "\n",
        "# determine color vector\n",
        "colors = ColorVector(properties['yr_built'].values, 20, 'coolwarm')\n",
        "\n",
        "# create base map\n",
        "m = folium.Map(location=[np.mean(properties.lat), np.mean(properties.long)], \n",
        "               tiles = 'Stamen Toner', zoom_start = 13)\n",
        "\n",
        "# loop through properties to add map layers\n",
        "for i in range(len(lats)):\n",
        "    folium.Circle(location=[lats[i], lngs[i]], \n",
        "                  popup = (\"\"\"<b>{}</b><br>Year Built: {}\"\"\".format(addresses[i], years[i])),\n",
        "                  radius = 20, \n",
        "                  color = colors[i],\n",
        "                  fill = True,\n",
        "                  fill_color = colors[i], \n",
        "                  fill_opacity=.30).add_to(m)\n",
        "    \n",
        "# save map as html file    \n",
        "m.save('view-1.html')"
      ],
      "metadata": {
        "id": "gctdY4DeeaVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "this view shows clusters of homes built in similar time periods and paints a picture of development over time.\n",
        "\n",
        "the color spectrum plots blue for older houses and red for newer houses."
      ],
      "metadata": {
        "id": "u7szKzgsedOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# stylize as currency\n",
        "dollar_vals = []\n",
        "for i in range(0, len(vals)):\n",
        "    dollar_vals = '${:0,.0f}'.format(vals[i]).replace('$-','-$')\n",
        "    \n",
        "# stylize as number (commas)\n",
        "num_sqfts = []\n",
        "for i in range(0, len(sqft)):\n",
        "    num_sqft = '{:0,.0f}'.format(sqft[i])\n",
        "    num_sqfts.append(num_sqft)\n",
        "    \n",
        "# determine color vector    \n",
        "colors = ColorVector(properties['price'].values, 10, 'plasma')\n",
        "ColorCategories('price', colors)\n",
        "\n",
        "# create the base map\n",
        "m = folium.Map(location=[np.mean(properties.lat), np.mean(properties.long)], \n",
        "               tiles = 'Stamen Toner', zoom_start = 13)\n",
        "\n",
        "# loop through properties to add map layers\n",
        "for i in range(len(lats)):\n",
        "    folium.Circle(location=[lats[i], lngs[i]], \n",
        "                  popup = (\"\"\"<b>{}</b><br>{}<br>{} sq. ft.<br>\"\"\".format(addresses[i], vals[i], sqft[i])),\n",
        "                  radius = 20, \n",
        "                  color = colors[i],\n",
        "                  fill = True,\n",
        "                  fill_color = colors[i], \n",
        "                  fill_opacity=.30).add_to(m)\n",
        "# save map as html file      \n",
        "m.save('view-2.html')"
      ],
      "metadata": {
        "id": "U02Hm7F8efUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this heatmap, the brighter the dot the higher the assessed value. Clicking on a circle reveals the total assessed value for the current tax year as well as the square footage of the home."
      ],
      "metadata": {
        "id": "5gj7GQr4ehmp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting Price"
      ],
      "metadata": {
        "id": "6xh0LBJQVIFE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## simple linear regression"
      ],
      "metadata": {
        "id": "wYn6EcIQTwM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "print(\"done\")"
      ],
      "metadata": {
        "id": "Qfu-PTt-TslJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# simple linear regression to explore features we think are interesting\n",
        "\n",
        "#Define target 'y'(dependendent variable) and features 'X'(independent variables or predictors).\n",
        "import statsmodels.formula.api as smf\n",
        "y_2 = df['price']\n",
        "X_2 = df.drop('price',axis=1)\n",
        "#Test each continus variable as a standalone linear regression.\n",
        "col_names = X_2.select_dtypes('float').columns\n",
        "results = [['ind_var', 'r_squared', 'intercept', 'slope', 'p-value' ]]\n",
        "for idx, val in enumerate(col_names):\n",
        "    print (\"Selling price~\" + val)\n",
        "    print (\"------------------------------\")\n",
        "\n",
        "    f = 'price~' + val\n",
        "    model = smf.ols(formula=f, data=df).fit()\n",
        "    X_new = pd.DataFrame({val: [X_2[val].min(), X_2[val].max()]});\n",
        "    preds = model.predict(X_new)\n",
        "    results.append([val, model.rsquared, model.params[0], model.params[1], model.pvalues[1] ])\n",
        "    print(results[idx+1])"
      ],
      "metadata": {
        "id": "nDduQw7ATuOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define target 'y'(dependendent variable) and features 'X'(independent variables or predictors).\n",
        "import statsmodels.formula.api as smf\n",
        "y_2 = df['price']\n",
        "X_2 = df.drop('price',axis=1)\n",
        "#Test each continus variable as a standalone linear regression.\n",
        "col_names = X_2.select_dtypes('int').columns\n",
        "results = [['ind_var', 'r_squared', 'intercept', 'slope', 'p-value' ]]\n",
        "for idx, val in enumerate(col_names):\n",
        "    print (\"Selling price~\" + val)\n",
        "    print (\"------------------------------\")\n",
        "\n",
        "    f = 'price~' + val\n",
        "    model = smf.ols(formula=f, data=df).fit()\n",
        "    X_new = pd.DataFrame({val: [X_2[val].min(), X_2[val].max()]});\n",
        "    preds = model.predict(X_new)\n",
        "    results.append([val, model.rsquared, model.params[0], model.params[1], model.pvalues[1] ])\n",
        "    print(results[idx+1])"
      ],
      "metadata": {
        "id": "wVkM2SIjTyo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_yreno = [col for col in X_2.columns if 'yr_renovated' in col]\n",
        "cols_zipcode = [col for col in X_2.columns if 'zipcode' in col]\n",
        "cols_grade = [col for col in X_2.columns if 'grade' in col]\n",
        "cols=[cols_yreno,cols_zipcode,cols_grade]\n",
        "\n",
        "for col in cols:\n",
        "    sum_cols = \"+\".join(col)\n",
        "    f = \"price ~\" + sum_cols\n",
        "    model = smf.ols(formula= f, data= df).fit()\n",
        "    print(model.summary())"
      ],
      "metadata": {
        "id": "-oZX88hTT0SI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RFE"
      ],
      "metadata": {
        "id": "CEiwI1aHUXGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dictionary to store our rankings\n",
        "ranks = {}\n",
        "# Create our function which stores the feature rankings to the ranks dictionary\n",
        "def ranking(ranks, names, order=1):\n",
        "    minmax = MinMaxScaler()\n",
        "    ranks = minmax.fit_transform(order*np.array([ranks]).T).T[0]\n",
        "    ranks = map(lambda x: round(x,2), ranks)\n",
        "    return dict(zip(names, ranks))"
      ],
      "metadata": {
        "id": "UwAtno97UYZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colnames = X.columns"
      ],
      "metadata": {
        "id": "xX2EmcViUnqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct our Linear Regression model\n",
        "lr = LinearRegression(normalize=True)\n",
        "lr.fit(X,y)\n",
        "#stop the search when only the last feature is left\n",
        "rfe = RFE(lr, n_features_to_select=1, verbose =3 )\n",
        "rfe.fit(X,y)\n",
        "ranks[\"RFE\"] = ranking(list(map(float, rfe.ranking_)), colnames, order=-1)"
      ],
      "metadata": {
        "id": "DhC9VAl1UfnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Linear Regression\n",
        "lr = LinearRegression(normalize=True)\n",
        "lr.fit(X,y)\n",
        "ranks[\"LinReg\"] = ranking(np.abs(lr.coef_), colnames)\n",
        "\n",
        "# Using Ridge \n",
        "ridge = Ridge(alpha = 7)\n",
        "ridge.fit(X,y)\n",
        "ranks['Ridge'] = ranking(np.abs(ridge.coef_), colnames)\n",
        "\n",
        "# Using Lasso\n",
        "lasso = Lasso(alpha=.05)\n",
        "lasso.fit(X, y)\n",
        "ranks[\"Lasso\"] = ranking(np.abs(lasso.coef_), colnames)\n",
        "\n",
        "rf = RandomForestRegressor(n_jobs=-1, n_estimators=50, verbose=3)\n",
        "rf.fit(X,y)\n",
        "ranks[\"RF\"] = ranking(rf.feature_importances_, colnames)"
      ],
      "metadata": {
        "id": "-ZAOV8RsUhyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = {}\n",
        "for name in colnames:\n",
        "    r[name] = round(np.mean([ranks[method][name] \n",
        "                             for method in ranks.keys()]), 2)\n",
        " \n",
        "methods = sorted(ranks.keys())\n",
        "ranks[\"Mean\"] = r\n",
        "methods.append(\"Mean\")\n",
        " \n",
        "print(\"\\t%s\" % \"\\t\".join(methods))\n",
        "for name in colnames:\n",
        "    print(\"%s\\t%s\" % (name, \"\\t\".join(map(str, \n",
        "                         [ranks[method][name] for method in methods]))))"
      ],
      "metadata": {
        "id": "TfoiOAjfUk0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meanplot = pd.DataFrame(list(r.items()), columns= ['Feature','Mean Ranking'])\n",
        "\n",
        "# Sort the dataframe\n",
        "meanplot = meanplot.sort_values('Mean Ranking', ascending=False)"
      ],
      "metadata": {
        "id": "cjvF86oIUsbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's plot the ranking of the features\n",
        "sns.factorplot(x=\"Mean Ranking\", y=\"Feature\", data = meanplot, kind=\"bar\", size=4, aspect=1.9, palette='cubehelix_r')"
      ],
      "metadata": {
        "id": "P8rTbkMaUuN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## linear regression"
      ],
      "metadata": {
        "id": "IAZO_jJ5T4-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('price',axis=1)\n",
        "y = df['price']"
      ],
      "metadata": {
        "id": "wkeU3oBMT2Ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "o7PmseD5T8PZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state = 101)\n",
        "print(\"train:{}{}\\n rest:{}{}\".format(X_train.shape,y_train.shape,X_test.shape, y_test.shape))"
      ],
      "metadata": {
        "id": "EqZASsgjT6we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stats OLS\n",
        "model = sm.OLS(y_train, X_train)\n",
        "results = model.fit()\n",
        "print(results.summary())"
      ],
      "metadata": {
        "id": "Jv76U4C2T9U6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "N2AFCZHmUAVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(true, predicted, train=True):  \n",
        "    mae = metrics.mean_absolute_error(true, predicted)\n",
        "    mse = metrics.mean_squared_error(true, predicted)\n",
        "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
        "    r2_square = metrics.r2_score(true, predicted)\n",
        "    if train:\n",
        "        print(\"========Training Result=======\")\n",
        "        print('MAE: ', mae)\n",
        "        print('MSE: ', mse)\n",
        "        print('RMSE: ', rmse)\n",
        "        print('R2 Square: ', r2_square)\n",
        "    elif not train:\n",
        "        print(\"=========Testing Result=======\")\n",
        "        print('MAE: ', mae)\n",
        "        print('MSE: ', mse)\n",
        "        print('RMSE: ', rmse)\n",
        "        print('R2 Square: ', r2_square)"
      ],
      "metadata": {
        "id": "DxOeTahFUDCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation(y_test, results.predict(X_test),train = False)"
      ],
      "metadata": {
        "id": "HzoJOtpTUEtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "print(\"accuracy\", lin_reg.score(X_test, y_test))\n",
        "evaluation(y_train, lin_reg.predict(X_train),train = True)\n",
        "evaluation(y_test, lin_reg.predict(X_test),train = False)"
      ],
      "metadata": {
        "id": "JXQwLJJ2UGSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ],
      "metadata": {
        "id": "jcFZVZR-UJFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linreg = LinearRegression()\n",
        "def linReg(X, y):  \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "    linreg.fit(X_train, y_train)\n",
        "    y_hat = linreg.predict(X_test)\n",
        "    y_hat_train = linreg.predict(X_train)\n",
        "    print('R_squared Score:', linreg.score(X, y))\n",
        "    #Display errors\n",
        "    print('Mean Absolute Error:', mean_absolute_error(y_test, y_hat))\n",
        "    print('Root Mean Squared Error test:', np.sqrt(mean_squared_error(y_test, y_hat)))\n",
        "    print('Root Mean Squared Error train:', np.sqrt(mean_squared_error(y_train, y_hat_train)))\n",
        "    #Compare predicted and actual values\n",
        "    print('Mean Predicted Selling Price:', y_hat.mean())\n",
        "    print('Mean Selling Price:', y_test.mean())\n",
        "    score = cross_val_score(linreg, X, y,cv=10, scoring=\"r2\")\n",
        "    print('R_squared Mean Score:',score.mean())\n",
        "    print(score)\n",
        "    return linreg\n",
        "linReg(X,y)"
      ],
      "metadata": {
        "id": "P-c0D0HoUKnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LR with RFE"
      ],
      "metadata": {
        "id": "_6w1dq7JU2oh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\tfor i in range(2, 18):\n",
        "\t\trfe = RFE(estimator=LinearRegression(), n_features_to_select=i)\n",
        "\t\tmodel = LinearRegression()\n",
        "\t\tmodels[str(i)] = Pipeline(steps=[('s',rfe),('m',model)])\n",
        "\treturn models\n",
        " \n",
        "# evaluate a give model using cross-validation\n",
        "def evaluate_model(model, X, y):\n",
        "\t#cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\tscores = cross_val_score(model, X, y, scoring='r2', cv=10, n_jobs=-1, error_score='raise')\n",
        "\treturn scores\n",
        " \n",
        "\n",
        "# get the models to evaluate\n",
        "models = get_models()\n",
        "# evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\tscores = evaluate_model(model, X, y)\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        "# plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)"
      ],
      "metadata": {
        "id": "9l_NBcPJUNLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Polynomial"
      ],
      "metadata": {
        "id": "7nI0HuGfVAmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "polynomial_features= PolynomialFeatures(degree=2)\n",
        "Xp= polynomial_features.fit_transform(X_train)\n",
        "Xpr= polynomial_features.fit_transform(X)\n",
        "Xpt =  polynomial_features.fit_transform(X_test)\n",
        "import statsmodels.api as sm\n",
        "\n",
        "model_poly = sm.OLS(y_train, Xp).fit()\n",
        "#print(model_poly.summary())\n",
        "\n",
        "print(\"R2: \", model_poly.rsquared)\n",
        "evaluation(y_test, model_poly.predict(Xpt),train = False)"
      ],
      "metadata": {
        "id": "2w5W3m2iU8gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "lin_reg2 = LinearRegression()\n",
        "lin_reg2.fit(Xp,y_train)\n",
        "yhat = lin_reg2.predict(Xpt)\n",
        "y_hat_train = lin_reg2.predict(Xp)\n",
        "print('Mean Absolute Error:', mean_absolute_error(y_test, yhat))\n",
        "print('Root Mean Squared Error test:', np.sqrt(mean_squared_error(y_test, yhat)))\n",
        "print('Root Mean Squared Error train:', np.sqrt(mean_squared_error(y_train, y_hat_train)))\n",
        "print('Mean Predicted Selling Price:', yhat.mean())\n",
        "print('Mean Selling Price:', y_test.mean())\n",
        "score = cross_val_score(lin_reg2, Xpr, y,cv=10, scoring=\"r2\")\n",
        "print('R_squared Mean Score:',score.mean())\n",
        "print(score)"
      ],
      "metadata": {
        "id": "-3Tm999jVLlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ridge"
      ],
      "metadata": {
        "id": "dkTAEStAVQrh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "alpha = [0.01, 0.1, 0.5, 1, 1.5, 2, 2.5, 3, 5, 8, 10, 15]\n",
        "r2=[]\n",
        "mae = []\n",
        "rmse = []\n",
        "r2_mean = []\n",
        "yhat_mean = []\n",
        "ytest_mean = []\n",
        "for i in range(len(alpha)):\n",
        "  RidgeModel = Ridge(alpha = alpha[i])\n",
        "  RidgeModel.fit(X_train, y_train)\n",
        "  yhat = RidgeModel.predict(X_test)\n",
        "  y_hat_train = RidgeModel.predict(X_train)\n",
        "  #print(\"The R^2 Score value for the training data is : \" + str(RidgeModel.score(x_train_pr, y_train)))\n",
        "  #print(\"The R^2 Score value for the testing data is : \" + str(RidgeModel.score(x_test_pr, y_test)))\n",
        "  r2.append(RidgeModel.score(X_test, y_test))\n",
        "  #print('Mean Absolute Error:', mean_absolute_error(y_test, yhat))\n",
        "  mae.append(mean_absolute_error(y_test, yhat))\n",
        "  #print('Root Mean Squared Error test:', np.sqrt(mean_squared_error(y_test, yhat)))\n",
        "  rmse.append(np.sqrt(mean_squared_error(y_test, yhat)))\n",
        "  #print('Root Mean Squared Error train:', np.sqrt(mean_squared_error(y_train, y_hat_train)))\n",
        "  #print('Mean Predicted Selling Price:', yhat.mean())\n",
        "  #print('Mean Selling Price:', y_test.mean())\n",
        "  yhat_mean.append(yhat.mean())\n",
        "  ytest_mean.append(y_test.mean())\n",
        "  score = cross_val_score(RidgeModel, X, y,cv=10, scoring=\"r2\")\n",
        "  #print('R_squared Mean Score:',score.mean())\n",
        "  r2_mean.append(score.mean())\n",
        "  # print(score)"
      ],
      "metadata": {
        "id": "hNDwoHgDVNlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_mean"
      ],
      "metadata": {
        "id": "VsXdMypjVS-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,10))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "# Plotting\n",
        "#plt.figure(figsize=(18, 8))\n",
        "plt.plot(alpha, r2_mean, 'bo-', label=r'mean $R^2$ of 10-fold CV', color=\"darkblue\", alpha=0.6, linewidth=3)\n",
        "#plt.plot(val_r_squared, 'bo-', label=r'$R^2$ Val set', color=\"darkred\", alpha=0.6, linewidth=3)\n",
        "plt.xlabel('Alpha value'); plt.ylabel(r'$R^2$')\n",
        "plt.title(r'Evaluate ridge regression $R^2$ with different alphas')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "# Plotting\n",
        "#plt.figure(figsize=(18, 8))\n",
        "plt.plot(alpha, rmse, 'bo-', label='RMSE of testing set', color=\"darkblue\", alpha=0.6, linewidth=3)\n",
        "#plt.plot(val_r_squared, 'bo-', label=r'$R^2$ Val set', color=\"darkred\", alpha=0.6, linewidth=3)\n",
        "plt.xlabel('Alpha value'); plt.ylabel('RMSE')\n",
        "plt.title(r'Evaluate ridge regression RMSE with different alphas')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "\n",
        "\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "# Plotting\n",
        "#plt.figure(figsize=(18, 8))\n",
        "plt.plot(alpha, mae, 'bo-', label='MAE of testing set', color=\"darkblue\", alpha=0.6, linewidth=3)\n",
        "#plt.plot(val_r_squared, 'bo-', label=r'$R^2$ Val set', color=\"darkred\", alpha=0.6, linewidth=3)\n",
        "plt.xlabel('Alpha value'); plt.ylabel('MAE')\n",
        "plt.title(r'Evaluate ridge regression MAE with different alphas')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "# Plotting\n",
        "#plt.figure(figsize=(18, 8))\n",
        "plt.plot(alpha, yhat_mean, 'bo-', label='prediction of testing set', color=\"darkblue\", alpha=0.6, linewidth=3)\n",
        "plt.plot(alpha, ytest_mean, 'bo-', label='true value of testing set', color=\"darkred\", alpha=0.6, linewidth=3)\n",
        "plt.xlabel('Alpha value'); plt.ylabel('Price')\n",
        "plt.title(r'Evaluate ridge regression Prices ith different alphas')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b5QGIQqbVUhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ridge with poly degree = 2"
      ],
      "metadata": {
        "id": "mOshVWfDVc0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pr = PolynomialFeatures(degree = 2)\n",
        "x_train_pr = pr.fit_transform(X_train)\n",
        "x_test_pr = pr.fit_transform(X_test)\n",
        "\n",
        "mae = []\n",
        "rmse = []\n",
        "r2_mean = []\n",
        "yhat_mean = []\n",
        "ytest_mean = []\n",
        "for i in range(len(alpha)):\n",
        "  RidgeModel = Ridge(alpha = alpha[i])\n",
        "  RidgeModel.fit(x_train_pr, y_train)\n",
        "  yhat = RidgeModel.predict(x_test_pr)\n",
        "  y_hat_train = RidgeModel.predict(x_train_pr)\n",
        "  #print(\"The R^2 Score value for the training data is : \" + str(RidgeModel.score(x_train_pr, y_train)))\n",
        "  #print(\"The R^2 Score value for the testing data is : \" + str(RidgeModel.score(x_test_pr, y_test)))\n",
        "  r2.append(RidgeModel.score(x_test_pr, y_test))\n",
        "  #print('Mean Absolute Error:', mean_absolute_error(y_test, yhat))\n",
        "  mae.append(mean_absolute_error(y_test, yhat))\n",
        "  #print('Root Mean Squared Error test:', np.sqrt(mean_squared_error(y_test, yhat)))\n",
        "  rmse.append(np.sqrt(mean_squared_error(y_test, yhat)))\n",
        "  #print('Root Mean Squared Error train:', np.sqrt(mean_squared_error(y_train, y_hat_train)))\n",
        "  #print('Mean Predicted Selling Price:', yhat.mean())\n",
        "  #print('Mean Selling Price:', y_test.mean())\n",
        "  yhat_mean.append(yhat.mean())\n",
        "  ytest_mean.append(y_test.mean())\n",
        "  score = cross_val_score(RidgeModel, x_pr, y,cv=10, scoring=\"r2\")\n",
        "  #print('R_squared Mean Score:',score.mean())\n",
        "  r2_mean.append(score.mean())\n",
        "  # print(score)"
      ],
      "metadata": {
        "id": "0M6YRRM9VXJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_mean"
      ],
      "metadata": {
        "id": "kGU1TtsmVe_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,10))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "# Plotting\n",
        "#plt.figure(figsize=(18, 8))\n",
        "plt.plot(alpha, r2_mean, 'bo-', label=r'mean $R^2$ of 10-fold CV', color=\"darkblue\", alpha=0.6, linewidth=3)\n",
        "#plt.plot(val_r_squared, 'bo-', label=r'$R^2$ Val set', color=\"darkred\", alpha=0.6, linewidth=3)\n",
        "plt.xlabel('Alpha value'); plt.ylabel(r'$R^2$')\n",
        "plt.title(r'Evaluate ridge regression $R^2$ with different alphas')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "# Plotting\n",
        "#plt.figure(figsize=(18, 8))\n",
        "plt.plot(alpha, rmse, 'bo-', label='RMSE of testing set', color=\"darkblue\", alpha=0.6, linewidth=3)\n",
        "#plt.plot(val_r_squared, 'bo-', label=r'$R^2$ Val set', color=\"darkred\", alpha=0.6, linewidth=3)\n",
        "plt.xlabel('Alpha value'); plt.ylabel('RMSE')\n",
        "plt.title(r'Evaluate ridge regression RMSE with different alphas')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "\n",
        "\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "# Plotting\n",
        "#plt.figure(figsize=(18, 8))\n",
        "plt.plot(alpha, mae, 'bo-', label='MAE of testing set', color=\"darkblue\", alpha=0.6, linewidth=3)\n",
        "#plt.plot(val_r_squared, 'bo-', label=r'$R^2$ Val set', color=\"darkred\", alpha=0.6, linewidth=3)\n",
        "plt.xlabel('Alpha value'); plt.ylabel('MAE')\n",
        "plt.title(r'Evaluate ridge regression MAE with different alphas')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "# Plotting\n",
        "#plt.figure(figsize=(18, 8))\n",
        "plt.plot(alpha, yhat_mean, 'bo-', label='prediction of testing set', color=\"darkblue\", alpha=0.6, linewidth=3)\n",
        "plt.plot(alpha, ytest_mean, 'bo-', label='true value of testing set', color=\"darkred\", alpha=0.6, linewidth=3)\n",
        "plt.xlabel('Alpha value'); plt.ylabel('Price')\n",
        "plt.title(r'Evaluate ridge regression Prices ith different alphas')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vCdNGNqjVkQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = [0.01, 0.1, 0.5, 1, 1.5, 2, 2.5, 3, 5, 8, 10, 15]\n",
        "pr = PolynomialFeatures(degree = 3)\n",
        "x_train_pr = pr.fit_transform(X_train)\n",
        "x_test_pr = pr.fit_transform(X_test)\n",
        "\n",
        "r2 = []\n",
        "for i in range(len(alpha)):\n",
        "  RidgeModel = Ridge(alpha = alpha[i])\n",
        "  RidgeModel.fit(x_train_pr, y_train)\n",
        "  yhat = RidgeModel.predict(x_test_pr)\n",
        "  y_hat_train = RidgeModel.predict(x_train_pr)\n",
        "  #print(\"The R^2 Score value for the training data is : \" + str(RidgeModel.score(x_train_pr, y_train)))\n",
        "  #print(\"The R^2 Score value for the testing data is : \" + str(RidgeModel.score(x_test_pr, y_test)))\n",
        "  r2.append(RidgeModel.score(x_test_pr, y_test))"
      ],
      "metadata": {
        "id": "4eHEtPkWVmXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2"
      ],
      "metadata": {
        "id": "5XIjKwWUVo0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## lasso"
      ],
      "metadata": {
        "id": "2mS4doKZVqgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Lasso_Regression(x_test, y_test, x_train, y_train, min_el, max_el):\n",
        "    \n",
        "    # Create a vector of lambdas\n",
        "    ells = np.linspace(min_el, max_el, 50)\n",
        "    num_lambdas = len(ells)\n",
        "    num_predictors = np.shape(x_train)[1]\n",
        "    \n",
        "    # Empty arrays to store r2 values and coefficients\n",
        "    train_r_squared = np.zeros(num_lambdas)\n",
        "    test_r_squared = np.zeros(num_lambdas)\n",
        "    coeff_a = np.zeros((num_lambdas, num_predictors))\n",
        "    test_mse = np.zeros(num_lambdas)\n",
        "    r2_mean = []\n",
        "    mae = []\n",
        "    rmse = []\n",
        "    yhat_mean = []\n",
        "    ytest_mean = []\n",
        "\n",
        "    # Loop\n",
        "    for i, ell in enumerate(ells):\n",
        "        \n",
        "        # Ridge regression\n",
        "        reg = Lasso_Reg(alpha=ell)\n",
        "        reg.fit(x_train, y_train)\n",
        "       # val_mse[i] = np.sum((y_val-reg.predict(x_val))**2)/float(len(y_val))\n",
        "        test_mse[i] = np.sum((y_test-reg.predict(x_test))**2)/float(len(y_test))\n",
        "        yhat = reg.predict(x_test)\n",
        "        y_hat_train = reg.predict(x_train)\n",
        "\n",
        "        # Calculate R2\n",
        "        r2_test = reg.score(x_test, y_test)\n",
        "        #r2_val = reg.score(x_val, y_val)\n",
        "        r2_train = reg.score(x_train, y_train)\n",
        "        test_r_squared[i] = r2_test\n",
        "        train_r_squared[i] = r2_train\n",
        "        \n",
        "        mae.append(mean_absolute_error(y_test, yhat))\n",
        "        rmse.append(np.sqrt(mean_squared_error(y_test, yhat)))\n",
        "        yhat_mean.append(yhat.mean())\n",
        "        ytest_mean.append(y_test.mean())\n",
        "        #val_r_squared[i] = r2_val\n",
        "        coeff_a[i,:] = reg.coef_\n",
        "\n",
        "        evaluation(y_train, reg.predict(X_train),train = True)\n",
        "       # evaluation(y_val, reg.predict(X_val),train = False)\n",
        "        evaluation(y_test, reg.predict(X_test),train = False)\n",
        "\n",
        "        score = cross_val_score(reg, X, y,cv=10, scoring=\"r2\")\n",
        "        #print('R_squared Mean Score:',score.mean())\n",
        "        r2_mean.append(score.mean())\n",
        "\n",
        "\n",
        "        \n",
        "    return train_r_squared, test_r_squared, yhat_mean, ytest_mean, mae, rmse, ells, test_mse, r2_mean"
      ],
      "metadata": {
        "id": "tD8rPAVVVxQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_r_squared, test_r_squared, yhat_mean, ytest_mean, mae, rmse, lambdas, test_mse, r2_mean =  Lasso_Regression(X_test, y_test, X_train, y_train, -5,15) "
      ],
      "metadata": {
        "id": "FsOHppnmVxyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_mean"
      ],
      "metadata": {
        "id": "Vwmg7nzMV0ZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,10))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "# Plotting\n",
        "#plt.figure(figsize=(18, 8))\n",
        "plt.plot(lambdas, r2_mean, 'bo-', label=r'mean $R^2$ of 10-fold CV', color=\"darkblue\", alpha=0.6, linewidth=1)\n",
        "#plt.plot(val_r_squared, 'bo-', label=r'$R^2$ Val set', color=\"darkred\", alpha=0.6, linewidth=3)\n",
        "plt.xlabel('Alpha value'); plt.ylabel(r'$R^2$')\n",
        "plt.title(r'Evaluate lasso regression $R^2$ with different lambdas')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "# Plotting\n",
        "#plt.figure(figsize=(18, 8))\n",
        "plt.plot(lambdas, test_mse, 'bo-', label='RMSE of testing set', color=\"darkblue\", alpha=0.6, linewidth=1)\n",
        "#plt.plot(val_r_squared, 'bo-', label=r'$R^2$ Val set', color=\"darkred\", alpha=0.6, linewidth=3)\n",
        "plt.xlabel('Alpha value'); plt.ylabel('RMSE')\n",
        "plt.title(r'Evaluate lasso regression RMSE with different alphas')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "\n",
        "\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "# Plotting\n",
        "#plt.figure(figsize=(18, 8))\n",
        "plt.plot(lambdas, train_r_squared, 'bo-', label='MAE of testing set', color=\"darkblue\", alpha=0.6, linewidth=1)\n",
        "#plt.plot(val_r_squared, 'bo-', label=r'$R^2$ Val set', color=\"darkred\", alpha=0.6, linewidth=3)\n",
        "plt.xlabel('Alpha value'); plt.ylabel('MAE')\n",
        "plt.title(r'Evaluate lasso regression MAE with different alphas')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "# Plotting\n",
        "#plt.figure(figsize=(18, 8))\n",
        "plt.plot(lambdas, yhat_mean, 'bo-', label='prediction of testing set', color=\"darkblue\", alpha=0.6, linewidth=1)\n",
        "plt.plot(lambdas, ytest_mean, 'bo-', label='true value of testing set', color=\"darkred\", alpha=0.6, linewidth=1)\n",
        "plt.xlabel('Alpha value'); plt.ylabel('Price')\n",
        "plt.title(r'Evaluate lasso regression Prices ith different alphas')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "42pAH5ZlV2Zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN "
      ],
      "metadata": {
        "id": "rjG70q5wV_WM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mae = []\n",
        "rmse = []\n",
        "r2_mean = []\n",
        "yhat_mean = []\n",
        "ytest_mean = []\n",
        "r2 = []\n",
        "n_neighbors = [1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
        "for i in range(len(n_neighbors)):\n",
        "  knn = KNeighborsRegressor(n_neighbors=n_neighbors[i])\n",
        "  knn.fit(X_train, y_train)\n",
        "  yhat = knn.predict(X_test)\n",
        "  y_hat_train = knn.predict(X_train)\n",
        "  #print(\"The R^2 Score value for the training data is : \" + str(RidgeModel.score(x_train_pr, y_train)))\n",
        "  #print(\"The R^2 Score value for the testing data is : \" + str(RidgeModel.score(x_test_pr, y_test)))\n",
        "  r2.append(knn.score(X_test, y_test))\n",
        "  #print('Mean Absolute Error:', mean_absolute_error(y_test, yhat))\n",
        "  mae.append(mean_absolute_error(y_test, yhat))\n",
        "  #print('Root Mean Squared Error test:', np.sqrt(mean_squared_error(y_test, yhat)))\n",
        "  rmse.append(np.sqrt(mean_squared_error(y_test, yhat)))\n",
        "  #print('Root Mean Squared Error train:', np.sqrt(mean_squared_error(y_train, y_hat_train)))\n",
        "  #print('Mean Predicted Selling Price:', yhat.mean())\n",
        "  #print('Mean Selling Price:', y_test.mean())\n",
        "  yhat_mean.append(yhat.mean())\n",
        "  ytest_mean.append(y_test.mean())\n",
        "  score = cross_val_score(knn, X, y,cv=10, scoring=\"r2\")\n",
        "  #print('R_squared Mean Score:',score.mean())\n",
        "  r2_mean.append(score.mean())\n",
        "  # print(score)"
      ],
      "metadata": {
        "id": "1A0CyLXGV5TA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_mean"
      ],
      "metadata": {
        "id": "EO358ljBWBPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,10))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "# Plotting\n",
        "#plt.figure(figsize=(18, 8))\n",
        "plt.plot(n_neighbors, r2_mean, 'bo-', label=r'mean $R^2$ of 10-fold CV', color=\"darkblue\", alpha=0.6, linewidth=1)\n",
        "#plt.plot(val_r_squared, 'bo-', label=r'$R^2$ Val set', color=\"darkred\", alpha=0.6, linewidth=3)\n",
        "plt.xlabel('Number of Neighbors'); plt.ylabel(r'$R^2$')\n",
        "plt.title(r'Evaluate KNN regressor $R^2$ with different number of neighbors')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "# Plotting\n",
        "#plt.figure(figsize=(18, 8))\n",
        "plt.plot(n_neighbors, rmse, 'bo-', label='RMSE of testing set', color=\"darkblue\", alpha=0.6, linewidth=1)\n",
        "#plt.plot(val_r_squared, 'bo-', label=r'$R^2$ Val set', color=\"darkred\", alpha=0.6, linewidth=3)\n",
        "plt.xlabel('Number of Neighbors'); plt.ylabel('RMSE')\n",
        "plt.title(r'Evaluate KNN regressor RMSE with different number of neighbors')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "\n",
        "\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "# Plotting\n",
        "#plt.figure(figsize=(18, 8))\n",
        "plt.plot(n_neighbors, mae, 'bo-', label='MAE of testing set', color=\"darkblue\", alpha=0.6, linewidth=1)\n",
        "#plt.plot(val_r_squared, 'bo-', label=r'$R^2$ Val set', color=\"darkred\", alpha=0.6, linewidth=3)\n",
        "plt.xlabel('number of neighbors'); plt.ylabel('MAE')\n",
        "plt.title(r'Evaluate KNN regressor MAE with different number of neighbors')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "# Plotting\n",
        "#plt.figure(figsize=(18, 8))\n",
        "plt.plot(n_neighbors, yhat_mean, 'bo-', label='prediction of testing set', color=\"darkblue\", alpha=0.6, linewidth=1)\n",
        "plt.plot(n_neighbors, ytest_mean, 'bo-', label='true value of testing set', color=\"darkred\", alpha=0.6, linewidth=1)\n",
        "plt.xlabel('number of neighbors'); plt.ylabel('Price')\n",
        "plt.title(r'Evaluate kNN regressor Prices with different number of neighbors')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XNrMc2i-WDAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree"
      ],
      "metadata": {
        "id": "yGXHHvVFWHVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {\n",
        "    'max_depth': range (5, 20),\n",
        "    'min_samples_leaf': [5, 10, 15, 20, 25]}\n",
        "\n",
        "grid_search = GridSearchCV(DecisionTreeRegressor(), parameters, cv=10, return_train_score=False, scoring='neg_mean_squared_error', n_jobs=4)\n",
        "grid_search.fit(X_train, y_train)\n",
        "grid_results = pd.DataFrame(grid_search.cv_results_)\n",
        "grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "NJfpuDEkWGD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mae = []\n",
        "rmse = []\n",
        "r2_mean = []\n",
        "yhat_mean = []\n",
        "ytest_mean = []\n",
        "r2 = []\n",
        "model = grid_search.best_estimator_\n",
        "yhat = model.predict(X_test)\n",
        "y_hat_train = model.predict(X_train)\n",
        "r2.append(model.score(X_test, y_test))\n",
        "mae.append(mean_absolute_error(y_test, yhat))\n",
        "rmse.append(np.sqrt(mean_squared_error(y_test, yhat)))\n",
        "print('Root Mean Squared Error train:', np.sqrt(mean_squared_error(y_train, y_hat_train)))\n",
        "print('Mean Predicted Selling Price:', yhat.mean())\n",
        "print('Mean Selling Price:', y_test.mean())\n",
        "yhat_mean.append(yhat.mean())\n",
        "ytest_mean.append(y_test.mean())\n",
        "score = cross_val_score(model, X, y,cv=10, scoring=\"r2\")\n",
        "print('R_squared Mean Score:',score.mean())\n",
        "r2_mean.append(score.mean())\n",
        "print(score)\n"
      ],
      "metadata": {
        "id": "EEXTJCaSWLHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_results.sort_values(by='rank_test_score').head(5)"
      ],
      "metadata": {
        "id": "IWKOg_-cWN0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_scores = grid_results.sort_values(by='rank_test_score')[['params', 'mean_test_score', 'std_test_score' ]]\n",
        "df_scores[['mean_test_score',  'std_test_score']] = np.sqrt(df_scores[['mean_test_score',  'std_test_score']].abs())\n",
        "df_scores.head()"
      ],
      "metadata": {
        "id": "1HnBQ3NMWPfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random forest"
      ],
      "metadata": {
        "id": "pal-95SBWShy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {\n",
        "    'max_depth': range (5, 20),\n",
        "    'n_estimators': [5, 10, 15, 20, 30]}\n",
        "\n",
        "grid_search = GridSearchCV(RandomForestRegressor(), parameters, cv=10, return_train_score=False, scoring='neg_mean_squared_error', n_jobs=4)\n",
        "grid_search.fit(X_train, y_train)\n",
        "grid_results = pd.DataFrame(grid_search.cv_results_)\n",
        "grid_search.best_estimator_\n"
      ],
      "metadata": {
        "id": "uqwPP6evWQyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mae = []\n",
        "rmse = []\n",
        "r2_mean = []\n",
        "yhat_mean = []\n",
        "ytest_mean = []\n",
        "r2 = []\n",
        "model = grid_search.best_estimator_\n",
        "yhat = model.predict(X_test)\n",
        "y_hat_train = model.predict(X_train)\n",
        "r2.append(model.score(X_test, y_test))\n",
        "mae.append(mean_absolute_error(y_test, yhat))\n",
        "rmse.append(np.sqrt(mean_squared_error(y_test, yhat)))\n",
        "print('Root Mean Squared Error train:', np.sqrt(mean_squared_error(y_train, y_hat_train)))\n",
        "print('Mean Predicted Selling Price:', yhat.mean())\n",
        "print('Mean Selling Price:', y_test.mean())\n",
        "yhat_mean.append(yhat.mean())\n",
        "ytest_mean.append(y_test.mean())\n",
        "score = cross_val_score(model, X, y,cv=10, scoring=\"r2\")\n",
        "print('R_squared Mean Score:',score.mean())\n",
        "r2_mean.append(score.mean())\n",
        "print(score)\n"
      ],
      "metadata": {
        "id": "h9FmumFkWcGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBRegressor"
      ],
      "metadata": {
        "id": "hmG9mVVcWd-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "param={\n",
        "    'objective': 'reg:linear',\n",
        "    'eta'      :0.02,\n",
        "    'eval_metric':'rmse',\n",
        "    'max_depth': 5,\n",
        "    'min_child_weight':3,\n",
        "    'subsample' : 0.8,\n",
        "    'colsample_bytree' : 0.8,\n",
        "    'silent': 1,\n",
        "    'seed' : 123\n",
        "}\n",
        "trn = xgb.DMatrix(X_train,label=y_train)\n",
        "tst = xgb.DMatrix(X_test,label=y_test)\n",
        "res = xgb.cv(param,trn,nfold=4,num_boost_round=2000,early_stopping_rounds=50,\n",
        "             stratified=True,show_stdv=True,metrics={'rmse'},maximize=False)\n",
        "min_index=np.argmin(res['test-rmse-mean'])\n",
        "\n",
        "model = xgb.train(param,trn,min_index,[(trn,'train'),(tst,'test')])\n",
        "pred = model.predict(tst)\n",
        "print('Test RMSE:', np.sqrt(mean_squared_error(y_test,pred)))"
      ],
      "metadata": {
        "id": "DShJZg0OWco2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_sq = ((pred-np.mean(y_test))**2).sum() / ((y_test - np.mean(y_test))**2).sum()\n",
        "print('R square is: ', r_sq)"
      ],
      "metadata": {
        "id": "rSALFzXlWhX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## personal pipeline"
      ],
      "metadata": {
        "id": "AKNTiCaOWmgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.model_selection import KFold, cross_val_score, train_test_split # Model evaluation\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler # Preprocessing\n",
        "from sklearn.linear_model import Lasso, Ridge, ElasticNet, RANSACRegressor, SGDRegressor, HuberRegressor, BayesianRidge # Linear models\n",
        "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, AdaBoostRegressor, GradientBoostingRegressor, ExtraTreesRegressor  # Ensemble methods\n",
        "from xgboost import XGBRegressor, plot_importance # XGBoost\n",
        "from sklearn.svm import SVR, SVC, LinearSVC  # Support Vector Regression\n",
        "from sklearn.tree import DecisionTreeRegressor # Decision Tree Regression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.pipeline import Pipeline # Streaming pipelines\n",
        "from sklearn.decomposition import KernelPCA, PCA # Dimensionality reduction\n",
        "from sklearn.feature_selection import SelectFromModel # Dimensionality reduction\n",
        "from sklearn.model_selection import learning_curve, validation_curve, GridSearchCV # Model evaluation\n",
        "from sklearn.base import clone # Clone estimator\n",
        "from sklearn.metrics import mean_squared_error as MSE"
      ],
      "metadata": {
        "id": "IowY7n4VWjTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipelines = []\n",
        "seed = 2\n",
        "\n",
        "pipelines.append(\n",
        "                (\"Scaled_Ridge\", \n",
        "                 Pipeline([\n",
        "                     (\"Scaler\", StandardScaler()), \n",
        "                     (\"Ridge\", Ridge(random_state=seed, alpha=1 ))\n",
        "                      ]))\n",
        "                )\n",
        "pipelines.append(\n",
        "                (\"Scaled_Lasso\", \n",
        "                 Pipeline([\n",
        "                     (\"Scaler\", StandardScaler()), \n",
        "                     (\"Lasso\", Lasso(random_state=seed, tol=1))\n",
        "                      ]))\n",
        "                )\n",
        "pipelines.append(\n",
        "                (\"Scaled_Elastic\", \n",
        "                 Pipeline([\n",
        "                     (\"Scaler\", StandardScaler()), \n",
        "                     (\"Lasso\", ElasticNet(random_state=seed))\n",
        "                      ]))\n",
        "                )\n",
        "\n",
        "pipelines.append(\n",
        "                (\"Scaled_SVR\",\n",
        "                 Pipeline([\n",
        "                     (\"Scaler\", StandardScaler()),\n",
        "                     (\"SVR\",  SVR(kernel='linear', C=1e2, degree=5))\n",
        "                 ])\n",
        "                )\n",
        "                )\n",
        "\n",
        "pipelines.append(\n",
        "                (\"Scaled_RF_reg\",\n",
        "                 Pipeline([\n",
        "                     (\"Scaler\", StandardScaler()),\n",
        "                     (\"RF\", RandomForestRegressor(random_state=seed))\n",
        "                 ])\n",
        "                )\n",
        "                )\n",
        "\n",
        "pipelines.append(\n",
        "                (\"Scaled_ET_reg\",\n",
        "                 Pipeline([\n",
        "                     (\"Scaler\", StandardScaler()),\n",
        "                     (\"ET\", ExtraTreesRegressor(random_state=seed))\n",
        "                 ])\n",
        "                )\n",
        "                )\n",
        "pipelines.append(\n",
        "                (\"Scaled_BR_reg\",\n",
        "                 Pipeline([\n",
        "                     (\"Scaler\", StandardScaler()),\n",
        "                     (\"BR\", BaggingRegressor(random_state=seed))\n",
        "                 ]))) \n",
        "\n",
        "pipelines.append(\n",
        "                (\"Scaled_Hub-Reg\",\n",
        "                 Pipeline([\n",
        "                     (\"Scaler\", StandardScaler()),\n",
        "                     (\"Hub-Reg\", HuberRegressor())\n",
        "                 ]))) \n",
        "pipelines.append(\n",
        "                (\"Scaled_BayRidge\",\n",
        "                 Pipeline([\n",
        "                     (\"Scaler\", StandardScaler()),\n",
        "                     (\"BR\", BayesianRidge())\n",
        "                 ]))) \n",
        "\n",
        "pipelines.append(\n",
        "                (\"Scaled_XGB_reg\",\n",
        "                 Pipeline([\n",
        "                     (\"Scaler\", StandardScaler()),\n",
        "                     (\"XGBR\", XGBRegressor(seed=seed))\n",
        "                 ]))) \n",
        "\n",
        "pipelines.append(\n",
        "                (\"Scaled_DT_reg\",\n",
        "                 Pipeline([\n",
        "                     (\"Scaler\", StandardScaler()),\n",
        "                     (\"DT_reg\", DecisionTreeRegressor())\n",
        "                 ]))) \n",
        "\n",
        "pipelines.append(\n",
        "                (\"Scaled_KNN_reg\",\n",
        "                 Pipeline([\n",
        "                     (\"Scaler\", StandardScaler()),\n",
        "                     (\"KNN_reg\", KNeighborsRegressor())\n",
        "                 ])))\n",
        "\n",
        "\n",
        "pipelines.append(\n",
        "                (\"Scaled_Gboost-Reg\",\n",
        "                 Pipeline([\n",
        "                     (\"Scaler\", StandardScaler()),\n",
        "                     (\"GBoost-Reg\", GradientBoostingRegressor())\n",
        "                 ])))\n",
        "\n",
        "pipelines.append(\n",
        "                (\"Scaled_RFR_PCA\",\n",
        "                 Pipeline([\n",
        "                     (\"Scaler\", StandardScaler()),\n",
        "                     (\"PCA\", PCA(n_components=3)),\n",
        "                     (\"XGB\", RandomForestRegressor())\n",
        "                 ])))\n",
        "\n",
        "pipelines.append(\n",
        "                (\"Scaled_XGBR_PCA\",\n",
        "                 Pipeline([\n",
        "                     (\"Scaler\", StandardScaler()),\n",
        "                     (\"PCA\", PCA(n_components=3)),\n",
        "                     (\"XGB\", XGBRegressor())\n",
        "                 ])))\n",
        "\n",
        "scoring = 'r2'\n",
        "n_folds = 10\n",
        "\n",
        "results, names  = [], [] \n",
        "\n",
        "for name, model  in pipelines:\n",
        "    kfold = KFold(n_splits=n_folds)\n",
        "    cv_results = cross_val_score(model, X, y, cv= kfold,\n",
        "                                 scoring=scoring, n_jobs=-1)    \n",
        "    names.append(name)\n",
        "    results.append(cv_results)    \n",
        "    msg = \"%s: %f (+/- %f)\" % (name, cv_results.mean(),  cv_results.std())\n",
        "    print(msg)"
      ],
      "metadata": {
        "id": "j9LeeofaWoY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# boxplot algorithm comparison\n",
        "fig = plt.figure(figsize=(15,6))\n",
        "fig.suptitle('Algorithm Comparison', fontsize=22)\n",
        "ax = fig.add_subplot(111)\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)\n",
        "ax.set_xticklabels(names)\n",
        "ax.set_xlabel(\"Algorithmn Name\", fontsize=20)\n",
        "ax.set_ylabel(\"R Squared Score of Models\", fontsize=18)\n",
        "ax.set_xticklabels(ax.get_xticklabels(),rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pO2_KgVmW7XI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DNN"
      ],
      "metadata": {
        "id": "6CkgGNLObIyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = df.sample(frac=0.8,random_state=0)\n",
        "test_dataset = df.drop(train_dataset.index)\n",
        "\n",
        "train_stats = train_dataset.describe()\n",
        "train_stats.pop('price')\n",
        "train_stats = train_stats.transpose()\n",
        "train_stats"
      ],
      "metadata": {
        "id": "_w9q97vqbKK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = train_dataset.pop('price')\n",
        "test_labels = test_dataset.pop('price')"
      ],
      "metadata": {
        "id": "mlryAbLmbNS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def norm(x):\n",
        "  return (x - train_stats['mean']) / train_stats['std']\n",
        "normed_train_data = norm(train_dataset)\n",
        "normed_test_data = norm(test_dataset)"
      ],
      "metadata": {
        "id": "dW_2m1N3bPd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import explained_variance_score"
      ],
      "metadata": {
        "id": "calF15C5bQ6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "  model = keras.Sequential([\n",
        "    layers.Dense(21, activation='relu', input_shape=[len(train_dataset.keys())]),\n",
        "    layers.Dense(21, activation='relu'),\n",
        "    layers.Dense(21, activation='relu'),\n",
        "    layers.Dense(1),\n",
        "  ])\n",
        "\n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "  model.compile(loss='mse',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae', 'mse'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "nE3PhbS-bT8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()"
      ],
      "metadata": {
        "id": "H2rb3okwbWWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "-ZrY1HK5bXsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class PrintDot(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    if epoch % 100 == 0: print('')\n",
        "    print('.', end='')\n",
        "\n",
        "EPOCHS = 1000\n",
        "\n",
        "history = model.fit(\n",
        "  normed_train_data, train_labels,\n",
        "  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
        "  callbacks=[PrintDot()])"
      ],
      "metadata": {
        "id": "50_p3JeebZQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions=model.predict(normed_test_data)\n",
        "print(\"The Variance Score :\", explained_variance_score(test_labels, predictions))"
      ],
      "metadata": {
        "id": "sEV6WMOKbash"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_absolute_error(test_labels,predictions)"
      ],
      "metadata": {
        "id": "qhezlrwkbcEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_squared_error(test_labels,predictions)**0.5"
      ],
      "metadata": {
        "id": "DYkWN_eKbdMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score(test_labels,predictions)"
      ],
      "metadata": {
        "id": "9oWp9Whmbe1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "  model = keras.Sequential([\n",
        "    layers.Dense(21, activation='relu', input_shape=[len(train_dataset.keys())]),\n",
        "    layers.Dense(21, activation='relu'),\n",
        "    layers.Dense(21, activation='relu'),\n",
        "    layers.Dense(1),\n",
        "  ])\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "  model.compile(loss='mse',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae', 'mse'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "fyRytfEJbgiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()"
      ],
      "metadata": {
        "id": "vNch_i-3biGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "kTCCu3rCbjkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class PrintDot(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    if epoch % 100 == 0: print('')\n",
        "    print('.', end='')\n",
        "\n",
        "EPOCHS = 1000\n",
        "\n",
        "history = model.fit(\n",
        "  normed_train_data, train_labels,\n",
        "  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
        "  callbacks=[PrintDot()])"
      ],
      "metadata": {
        "id": "jtpsUefdblEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions=model.predict(normed_test_data)\n",
        "print(\"The Variance Score :\", explained_variance_score(test_labels, predictions))"
      ],
      "metadata": {
        "id": "tXaf3P-7bpW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_squared_error(test_labels,predictions)**0.5"
      ],
      "metadata": {
        "id": "awf6gfbVbq6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_absolute_error(test_labels,predictions)"
      ],
      "metadata": {
        "id": "nG0KIpMgbu5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score(test_labels,predictions)"
      ],
      "metadata": {
        "id": "gdrAOxDubwFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# predicting log price"
      ],
      "metadata": {
        "id": "NfbIVT3eW_5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop(['id','price','log_price','sqft_living15','sqft_lot15','sqft_living','sqft_lot','sqft_above',\n",
        "              'sqft_basement','zipcode'],axis=1)\n",
        "y = data['log_price']"
      ],
      "metadata": {
        "id": "B0GXNGqhXhZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ols"
      ],
      "metadata": {
        "id": "v-c0MzyMYuYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# simple linear regression to explore features we think are interesting\n",
        "\n",
        "#Define target 'y'(dependendent variable) and features 'X'(independent variables or predictors).\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "#Test each continus variable as a standalone linear regression.\n",
        "col_names = X.select_dtypes('float').columns\n",
        "results = [['ind_var', 'r_squared', 'intercept', 'slope', 'p-value' ]]\n",
        "for idx, val in enumerate(col_names):\n",
        "    print (\"Selling price~\" + val)\n",
        "    print (\"------------------------------\")\n",
        "\n",
        "    f = 'price~' + val\n",
        "    model = smf.ols(formula=f, data=data).fit()\n",
        "    X_new = pd.DataFrame({val: [X[val].min(), X[val].max()]});\n",
        "    preds = model.predict(X_new)\n",
        "    results.append([val, model.rsquared, model.params[0], model.params[1], model.pvalues[1] ])\n",
        "    print(results[idx+1])"
      ],
      "metadata": {
        "id": "tnzrQbcKYsOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define target 'y'(dependendent variable) and features 'X'(independent variables or predictors).\n",
        "import statsmodels.formula.api as smf\n",
        "#Test each continus variable as a standalone linear regression.\n",
        "col_names = X.select_dtypes('int').columns\n",
        "results = [['ind_var', 'r_squared', 'intercept', 'slope', 'p-value' ]]\n",
        "for idx, val in enumerate(col_names):\n",
        "    print (\"Selling price~\" + val)\n",
        "    print (\"------------------------------\")\n",
        "\n",
        "    f = 'price~' + val\n",
        "    model = smf.ols(formula=f, data=data).fit()\n",
        "    X_new = pd.DataFrame({val: [X[val].min(), X[val].max()]});\n",
        "    preds = model.predict(X_new)\n",
        "    results.append([val, model.rsquared, model.params[0], model.params[1], model.pvalues[1] ])\n",
        "    print(results[idx+1])"
      ],
      "metadata": {
        "id": "YVQaEVg0YuAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RFE"
      ],
      "metadata": {
        "id": "4Z5hREbyZoSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ranks = {}\n",
        "colnames = X.columns\n",
        "# Using Linear Regression\n",
        "lr = LinearRegression(normalize=True)\n",
        "lr.fit(X,y)\n",
        "ranks[\"LinReg\"] = ranking(np.abs(lr.coef_), colnames)\n",
        "\n",
        "# Using Ridge \n",
        "ridge = Ridge(alpha = 7)\n",
        "ridge.fit(X,y)\n",
        "ranks['Ridge'] = ranking(np.abs(ridge.coef_), colnames)\n",
        "\n",
        "# Using Lasso\n",
        "lasso = Lasso(alpha=.05)\n",
        "lasso.fit(X, y)\n",
        "ranks[\"Lasso\"] = ranking(np.abs(lasso.coef_), colnames)\n",
        "\n",
        "rf = RandomForestRegressor(n_jobs=-1, n_estimators=50, verbose=3)\n",
        "rf.fit(X,y)\n",
        "ranks[\"RF\"] = ranking(rf.feature_importances_, colnames)\n",
        "\n",
        "r = {}\n",
        "for name in colnames:\n",
        "    r[name] = round(np.mean([ranks[method][name] \n",
        "                             for method in ranks.keys()]), 2)\n",
        " \n",
        "methods = sorted(ranks.keys())\n",
        "ranks[\"Mean\"] = r\n",
        "methods.append(\"Mean\")\n",
        " \n",
        "print(\"\\t%s\" % \"\\t\".join(methods))\n",
        "for name in colnames:\n",
        "    print(\"%s\\t%s\" % (name, \"\\t\".join(map(str, \n",
        "                         [ranks[method][name] for method in methods]))))"
      ],
      "metadata": {
        "id": "MvE7MQH-Znu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meanplot = pd.DataFrame(list(r.items()), columns= ['Feature','Mean Ranking'])\n",
        "\n",
        "# Sort the dataframe\n",
        "meanplot = meanplot.sort_values('Mean Ranking', ascending=False)"
      ],
      "metadata": {
        "id": "cyoUM9KUZ6lW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's plot the ranking of the features\n",
        "sns.factorplot(x=\"Mean Ranking\", y=\"Feature\", data = meanplot, kind=\"bar\", size=4, aspect=1.9, palette='cubehelix_r')"
      ],
      "metadata": {
        "id": "-fg5DhJBZ9bA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## linear regression"
      ],
      "metadata": {
        "id": "H3qinNpVZ-Jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state = 111)"
      ],
      "metadata": {
        "id": "cjmh2sF6Y0Ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stats OLS\n",
        "model = sm.OLS(y_train, X_train)\n",
        "results = model.fit()\n",
        "print(results.summary())"
      ],
      "metadata": {
        "id": "42kmSrhbY1wC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(true, predicted, train=True):  \n",
        "    mae = metrics.mean_absolute_error(true, predicted)\n",
        "    mse = metrics.mean_squared_error(true, predicted)\n",
        "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
        "    r2_square = metrics.r2_score(true, predicted)\n",
        "    if train:\n",
        "        print(\"========Training Result=======\")\n",
        "        print('MAE: ', mae)\n",
        "        print('MSE: ', mse)\n",
        "        print('RMSE: ', rmse)\n",
        "        print('R2 Square: ', r2_square)\n",
        "    elif not train:\n",
        "        print(\"=========Testing Result=======\")\n",
        "        print('MAE: ', mae)\n",
        "        print('MSE: ', mse)\n",
        "        print('RMSE: ', rmse)\n",
        "        print('R2 Square: ', r2_square)"
      ],
      "metadata": {
        "id": "PEx8THxWY3M_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation(y_train, results.predict(X_train),train = True)\n",
        "evaluation(y_test, results.predict(X_test),train = False)"
      ],
      "metadata": {
        "id": "YQt11C8JY5kQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linreg = LinearRegression()\n",
        "def linReg(X, y):  \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "    linreg.fit(X_train, y_train)\n",
        "    y_hat = linreg.predict(X_test)\n",
        "    y_hat_train = linreg.predict(X_train)\n",
        "    print('R_squared Score:', linreg.score(X, y))\n",
        "    #Display errors\n",
        "    print('Mean Absolute Error:', mean_absolute_error(y_test, y_hat))\n",
        "    print('Root Mean Squared Error test:', np.sqrt(mean_squared_error(y_test, y_hat)))\n",
        "    print('Root Mean Squared Error train:', np.sqrt(mean_squared_error(y_train, y_hat_train)))\n",
        "    #Compare predicted and actual values\n",
        "    print('Mean Predicted Selling Price:', y_hat.mean())\n",
        "    print('Mean Selling Price:', y_test.mean())\n",
        "    score = cross_val_score(linreg, X, y,cv=10, scoring=\"r2\")\n",
        "    print('R_squared Mean Score:',score.mean())\n",
        "    explained = cross_val_score(linreg, X, y,cv=10, scoring=\"explained_variance\")\n",
        "    print('Explained variance:',explained.mean())\n",
        "    print(score)\n",
        "    return linreg\n",
        "linReg(X,y)"
      ],
      "metadata": {
        "id": "ApfLq2PuY8vj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\tfor i in range(2, 18):\n",
        "\t\trfe = RFE(estimator=LinearRegression(), n_features_to_select=i)\n",
        "\t\tmodel = LinearRegression()\n",
        "\t\tmodels[str(i)] = Pipeline(steps=[('s',rfe),('m',model)])\n",
        "\treturn models\n",
        " \n",
        "# evaluate a give model using cross-validation\n",
        "def evaluate_model(model, X, y):\n",
        "\t#cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\tscores = cross_val_score(model, X, y, scoring='r2', cv=10, n_jobs=-1, error_score='raise')\n",
        "\treturn scores\n",
        " \n",
        "\n",
        "# get the models to evaluate\n",
        "models = get_models()\n",
        "# evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\tscores = evaluate_model(model, X, y)\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        "# plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)"
      ],
      "metadata": {
        "id": "wcOFFI7ZaFPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## polynomial"
      ],
      "metadata": {
        "id": "3yCAomRWY__y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "polyfeat=PolynomialFeatures(degree=2)\n",
        "xtrain_poly=polyfeat.fit_transform(X_train)\n",
        "xtest_poly=polyfeat.fit_transform(X_test)\n",
        "\n",
        "poly=LinearRegression()\n",
        "poly.fit(xtrain_poly,y_train)\n",
        "polypred=poly.predict(xtest_poly)\n",
        "\n",
        "print('Complex Model_3')\n",
        "mean_squared_error = metrics.mean_squared_error(y_test, polypred)\n",
        "print('Mean Squared Error (MSE) ', round(np.sqrt(mean_squared_error), 2))\n",
        "print('R-squared (training) ', round(poly.score(xtrain_poly, y_train), 3))\n",
        "print('R-squared (testing) ', round(poly.score(xtest_poly, y_test), 3))"
      ],
      "metadata": {
        "id": "VcwWK0wGZFun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "polynomial_features= PolynomialFeatures(degree=3)\n",
        "Xp= polynomial_features.fit_transform(X_train)\n",
        "Xpr= polynomial_features.fit_transform(X)\n",
        "Xpt =  polynomial_features.fit_transform(X_test)\n",
        "import statsmodels.api as sm\n",
        "\n",
        "model_poly = sm.OLS(y_train, Xp).fit()\n",
        "#print(model_poly.summary())\n",
        "\n",
        "print(\"R2: \", model_poly.rsquared)\n",
        "evaluation(y_test, model_poly.predict(Xpt),train = False)"
      ],
      "metadata": {
        "id": "B9F1K8UAZGRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ridge"
      ],
      "metadata": {
        "id": "R5u7zzX1ZKhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "alpha = [0.01, 0.1, 0.5, 1, 1.5, 2, 2.5, 3, 5, 8, 10, 15]\n",
        "r2=[]\n",
        "mae = []\n",
        "rmse = []\n",
        "r2_mean = []\n",
        "yhat_mean = []\n",
        "ytest_mean = []\n",
        "explained_var = []\n",
        "for i in range(len(alpha)):\n",
        "  RidgeModel = Ridge(alpha = alpha[i])\n",
        "  RidgeModel.fit(X_train, y_train)\n",
        "  yhat = RidgeModel.predict(X_test)\n",
        "  y_hat_train = RidgeModel.predict(X_train)\n",
        "  #print(\"The R^2 Score value for the training data is : \" + str(RidgeModel.score(x_train_pr, y_train)))\n",
        "  #print(\"The R^2 Score value for the testing data is : \" + str(RidgeModel.score(x_test_pr, y_test)))\n",
        "  r2.append(RidgeModel.score(X_test, y_test))\n",
        "  #print('Mean Absolute Error:', mean_absolute_error(y_test, yhat))\n",
        "  mae.append(mean_absolute_error(y_test, yhat))\n",
        "  #print('Root Mean Squared Error test:', np.sqrt(mean_squared_error(y_test, yhat)))\n",
        "  rmse.append(np.sqrt(mean_squared_error(y_test, yhat)))\n",
        "  #print('Root Mean Squared Error train:', np.sqrt(mean_squared_error(y_train, y_hat_train)))\n",
        "  #print('Mean Predicted Selling Price:', yhat.mean())\n",
        "  #print('Mean Selling Price:', y_test.mean())\n",
        "  yhat_mean.append(yhat.mean())\n",
        "  ytest_mean.append(y_test.mean())\n",
        "  score = cross_val_score(RidgeModel, X, y,cv=10, scoring=\"r2\")\n",
        "  #print('R_squared Mean Score:',score.mean())\n",
        "  explained = cross_val_score(RidgeModel, X, y,cv=10, scoring=\"explained_variance\")\n",
        "  #print('R_squared Mean Score:',explained.mean())\n",
        "  r2_mean.append(score.mean())\n",
        "  explained_var.append(explained.mean())\n",
        "  # print(score)"
      ],
      "metadata": {
        "id": "FebhiOwiZN_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,10))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "# Plotting\n",
        "#plt.figure(figsize=(18, 8))\n",
        "plt.plot(alpha, r2_mean, 'bo-', label=r'mean $R^2$ of 10-fold CV', color=\"darkblue\", alpha=0.6, linewidth=3)\n",
        "plt.plot(alpha, explained_var, 'bo-', label=r'mean explained variance of 10-fold CV', color=\"darkred\", alpha=0.6, linewidth=3)\n",
        "plt.xlabel('Alpha value'); plt.ylabel(r'$R^2$')\n",
        "plt.title(r'Evaluate ridge regression $R^2$ with different alphas')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "# Plotting\n",
        "#plt.figure(figsize=(18, 8))\n",
        "plt.plot(alpha, rmse, 'bo-', label='RMSE of testing set', color=\"darkblue\", alpha=0.6, linewidth=3)\n",
        "#plt.plot(val_r_squared, 'bo-', label=r'$R^2$ Val set', color=\"darkred\", alpha=0.6, linewidth=3)\n",
        "plt.xlabel('Alpha value'); plt.ylabel('RMSE')\n",
        "plt.title(r'Evaluate ridge regression RMSE with different alphas')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "\n",
        "\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "# Plotting\n",
        "#plt.figure(figsize=(18, 8))\n",
        "plt.plot(alpha, mae, 'bo-', label='MAE of testing set', color=\"darkblue\", alpha=0.6, linewidth=3)\n",
        "#plt.plot(val_r_squared, 'bo-', label=r'$R^2$ Val set', color=\"darkred\", alpha=0.6, linewidth=3)\n",
        "plt.xlabel('Alpha value'); plt.ylabel('MAE')\n",
        "plt.title(r'Evaluate ridge regression MAE with different alphas')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "# Plotting\n",
        "#plt.figure(figsize=(18, 8))\n",
        "plt.plot(alpha, yhat_mean, 'bo-', label='prediction of testing set', color=\"darkblue\", alpha=0.6, linewidth=3)\n",
        "plt.plot(alpha, ytest_mean, 'bo-', label='true value of testing set', color=\"darkred\", alpha=0.6, linewidth=3)\n",
        "plt.xlabel('Alpha value'); plt.ylabel('Price')\n",
        "plt.title(r'Evaluate ridge regression Prices ith different alphas')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IihI4nDiZOVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ridge + poly"
      ],
      "metadata": {
        "id": "yCUtAhTdZU11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pr = PolynomialFeatures(degree = 2)\n",
        "x_train_pr = pr.fit_transform(X_train)\n",
        "x_test_pr = pr.fit_transform(X_test)\n",
        "\n",
        "RidgeModel = Ridge(alpha = 0.1)\n",
        "RidgeModel.fit(x_train_pr, y_train)\n",
        "yhat = RidgeModel.predict(x_test_pr)\n",
        "y_hat_train = RidgeModel.predict(x_train_pr)\n",
        "\n",
        "print(\"The R^2 Score value for the training data is : \" + str(RidgeModel.score(x_train_pr, y_train)))\n",
        "print(\"The R^2 Score value for the testing data is : \" + str(RidgeModel.score(x_test_pr, y_test)))"
      ],
      "metadata": {
        "id": "54at53lKZQhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mae = []\n",
        "rmse = []\n",
        "r2_mean = []\n",
        "yhat_mean = []\n",
        "ytest_mean = []\n",
        "explained_var = []\n",
        "for i in range(len(alpha)):\n",
        "  RidgeModel = Ridge(alpha = alpha[i])\n",
        "  RidgeModel.fit(x_train_pr, y_train)\n",
        "  yhat = RidgeModel.predict(x_test_pr)\n",
        "  y_hat_train = RidgeModel.predict(x_train_pr)\n",
        "  #print(\"The R^2 Score value for the training data is : \" + str(RidgeModel.score(x_train_pr, y_train)))\n",
        "  #print(\"The R^2 Score value for the testing data is : \" + str(RidgeModel.score(x_test_pr, y_test)))\n",
        "  r2.append(RidgeModel.score(x_test_pr, y_test))\n",
        "  #print('Mean Absolute Error:', mean_absolute_error(y_test, yhat))\n",
        "  mae.append(mean_absolute_error(y_test, yhat))\n",
        "  #print('Root Mean Squared Error test:', np.sqrt(mean_squared_error(y_test, yhat)))\n",
        "  rmse.append(np.sqrt(mean_squared_error(y_test, yhat)))\n",
        "  #print('Root Mean Squared Error train:', np.sqrt(mean_squared_error(y_train, y_hat_train)))\n",
        "  #print('Mean Predicted Selling Price:', yhat.mean())\n",
        "  #print('Mean Selling Price:', y_test.mean())\n",
        "  yhat_mean.append(yhat.mean())\n",
        "  ytest_mean.append(y_test.mean())\n",
        "  score = cross_val_score(RidgeModel, x_pr, y,cv=10, scoring=\"r2\")\n",
        "  #print('R_squared Mean Score:',score.mean())\n",
        "  explained = cross_val_score(RidgeModel, x_pr, y , cv= 10, scoring = \"explained_variance\")\n",
        "  r2_mean.append(score.mean())\n",
        "  explained_var.append(explained.mean())\n",
        "  # print(score)"
      ],
      "metadata": {
        "id": "02qM0P6lZbni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,10))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "# Plotting\n",
        "#plt.figure(figsize=(18, 8))\n",
        "plt.plot(alpha, r2_mean, 'bo-', label=r'mean $R^2$ of 10-fold CV', color=\"darkblue\", alpha=0.6, linewidth=3)\n",
        "plt.plot(alpha, explained_var, 'bo-', label='mean explained variance of 10-fold CV', color=\"darkred\", alpha=0.6, linewidth=3)\n",
        "plt.xlabel('Alpha value'); plt.ylabel(r'$R^2$')\n",
        "plt.title(r'Evaluate ridge regression $R^2$ with different alphas')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "# Plotting\n",
        "#plt.figure(figsize=(18, 8))\n",
        "plt.plot(alpha, rmse, 'bo-', label='RMSE of testing set', color=\"darkblue\", alpha=0.6, linewidth=3)\n",
        "#plt.plot(val_r_squared, 'bo-', label=r'$R^2$ Val set', color=\"darkred\", alpha=0.6, linewidth=3)\n",
        "plt.xlabel('Alpha value'); plt.ylabel('RMSE')\n",
        "plt.title(r'Evaluate ridge regression RMSE with different alphas')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "\n",
        "\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "# Plotting\n",
        "#plt.figure(figsize=(18, 8))\n",
        "plt.plot(alpha, mae, 'bo-', label='MAE of testing set', color=\"darkblue\", alpha=0.6, linewidth=3)\n",
        "#plt.plot(val_r_squared, 'bo-', label=r'$R^2$ Val set', color=\"darkred\", alpha=0.6, linewidth=3)\n",
        "plt.xlabel('Alpha value'); plt.ylabel('MAE')\n",
        "plt.title(r'Evaluate ridge regression MAE with different alphas')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "# Plotting\n",
        "#plt.figure(figsize=(18, 8))\n",
        "plt.plot(alpha, yhat_mean, 'bo-', label='prediction of testing set', color=\"darkblue\", alpha=0.6, linewidth=3)\n",
        "plt.plot(alpha, ytest_mean, 'bo-', label='true value of testing set', color=\"darkred\", alpha=0.6, linewidth=3)\n",
        "plt.xlabel('Alpha value'); plt.ylabel('Price')\n",
        "plt.title(r'Evaluate ridge regression Prices ith different alphas')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wsXCs-M1ZcCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_mean"
      ],
      "metadata": {
        "id": "z3BHXfdeZeOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## lasso"
      ],
      "metadata": {
        "id": "OCdgXeBPZgSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Lasso_Regression(x_test, y_test, x_train, y_train, min_el, max_el):\n",
        "    \n",
        "    # Create a vector of lambdas\n",
        "    ells = np.linspace(min_el, max_el, 50)\n",
        "    num_lambdas = len(ells)\n",
        "    num_predictors = np.shape(x_train)[1]\n",
        "    \n",
        "    # Empty arrays to store r2 values and coefficients\n",
        "    train_r_squared = np.zeros(num_lambdas)\n",
        "    test_r_squared = np.zeros(num_lambdas)\n",
        "    coeff_a = np.zeros((num_lambdas, num_predictors))\n",
        "    test_mse = np.zeros(num_lambdas)\n",
        "    r2_mean = []\n",
        "    mae = []\n",
        "    rmse = []\n",
        "    yhat_mean = []\n",
        "    ytest_mean = []\n",
        "    explained_var = []\n",
        "\n",
        "    # Loop\n",
        "    for i, ell in enumerate(ells):\n",
        "        \n",
        "        # Ridge regression\n",
        "        reg = Lasso_Reg(alpha=ell)\n",
        "        reg.fit(x_train, y_train)\n",
        "       # val_mse[i] = np.sum((y_val-reg.predict(x_val))**2)/float(len(y_val))\n",
        "        test_mse[i] = np.sum((y_test-reg.predict(x_test))**2)/float(len(y_test))\n",
        "        yhat = reg.predict(x_test)\n",
        "        y_hat_train = reg.predict(x_train)\n",
        "\n",
        "        # Calculate R2\n",
        "        r2_test = reg.score(x_test, y_test)\n",
        "        #r2_val = reg.score(x_val, y_val)\n",
        "        r2_train = reg.score(x_train, y_train)\n",
        "        test_r_squared[i] = r2_test\n",
        "        train_r_squared[i] = r2_train\n",
        "        \n",
        "        mae.append(mean_absolute_error(y_test, yhat))\n",
        "        rmse.append(np.sqrt(mean_squared_error(y_test, yhat)))\n",
        "        yhat_mean.append(yhat.mean())\n",
        "        ytest_mean.append(y_test.mean())\n",
        "        #val_r_squared[i] = r2_val\n",
        "        coeff_a[i,:] = reg.coef_\n",
        "\n",
        "        #evaluation(y_train, reg.predict(X_train),train = True)\n",
        "       # evaluation(y_val, reg.predict(X_val),train = False)\n",
        "        #evaluation(y_test, reg.predict(X_test),train = False)\n",
        "\n",
        "        score = cross_val_score(reg, X, y,cv=10, scoring=\"r2\")\n",
        "        #print('R_squared Mean Score:',score.mean())\n",
        "        r2_mean.append(score.mean())\n",
        "\n",
        "        explained =  cross_val_score(reg, X, y,cv=10, scoring=\"explained_variance\")\n",
        "        explained_var.append(explained.mean())\n",
        "        \n",
        "    return train_r_squared, test_r_squared, yhat_mean, ytest_mean, mae, rmse, ells, test_mse, r2_mean,explained_var"
      ],
      "metadata": {
        "id": "Mi_T62sNZhDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_r_squared, test_r_squared, yhat_mean, ytest_mean, mae, rmse, lambdas, test_mse, r2_mean, explained_var=  Lasso_Regression(X_test, y_test, X_train, y_train, -5,15) "
      ],
      "metadata": {
        "id": "UK0l4ph1Zj3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN "
      ],
      "metadata": {
        "id": "UgTfM58PaOPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mae = []\n",
        "rmse = []\n",
        "r2_mean = []\n",
        "yhat_mean = []\n",
        "ytest_mean = []\n",
        "r2 = []\n",
        "explained_var = []\n",
        "n_neighbors = [1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
        "for i in range(len(n_neighbors)):\n",
        "  knn = KNeighborsRegressor(n_neighbors=n_neighbors[i])\n",
        "  knn.fit(X_train, y_train)\n",
        "  yhat = knn.predict(X_test)\n",
        "  y_hat_train = knn.predict(X_train)\n",
        "  #print(\"The R^2 Score value for the training data is : \" + str(RidgeModel.score(x_train_pr, y_train)))\n",
        "  #print(\"The R^2 Score value for the testing data is : \" + str(RidgeModel.score(x_test_pr, y_test)))\n",
        "  r2.append(knn.score(X_test, y_test))\n",
        "  #print('Mean Absolute Error:', mean_absolute_error(y_test, yhat))\n",
        "  mae.append(mean_absolute_error(y_test, yhat))\n",
        "  #print('Root Mean Squared Error test:', np.sqrt(mean_squared_error(y_test, yhat)))\n",
        "  rmse.append(np.sqrt(mean_squared_error(y_test, yhat)))\n",
        "  #print('Root Mean Squared Error train:', np.sqrt(mean_squared_error(y_train, y_hat_train)))\n",
        "  #print('Mean Predicted Selling Price:', yhat.mean())\n",
        "  #print('Mean Selling Price:', y_test.mean())\n",
        "  yhat_mean.append(yhat.mean())\n",
        "  ytest_mean.append(y_test.mean())\n",
        "  score = cross_val_score(knn, X, y,cv=10, scoring=\"r2\")\n",
        "  var = cross_val_score(knn, X, y,cv=10, scoring=\"explained_variance\")\n",
        "  #print('R_squared Mean Score:',score.mean())\n",
        "  r2_mean.append(score.mean())\n",
        "  explained_var.append(var.mean())\n",
        "  # print(score)"
      ],
      "metadata": {
        "id": "0PLN7CA_aKlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_mean"
      ],
      "metadata": {
        "id": "cR0fqDvEaPqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,10))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "# Plotting\n",
        "#plt.figure(figsize=(18, 8))\n",
        "plt.plot(n_neighbors, r2_mean, 'bo-', label=r'mean $R^2$ of 10-fold CV', color=\"darkblue\", alpha=0.6, linewidth=1)\n",
        "#plt.plot(val_r_squared, 'bo-', label=r'$R^2$ Val set', color=\"darkred\", alpha=0.6, linewidth=3)\n",
        "plt.xlabel('Number of Neighbors'); plt.ylabel(r'$R^2$')\n",
        "plt.title(r'Evaluate KNN regressor $R^2$ with different number of neighbors')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "# Plotting\n",
        "#plt.figure(figsize=(18, 8))\n",
        "plt.plot(n_neighbors, rmse, 'bo-', label='RMSE of testing set', color=\"darkblue\", alpha=0.6, linewidth=1)\n",
        "#plt.plot(val_r_squared, 'bo-', label=r'$R^2$ Val set', color=\"darkred\", alpha=0.6, linewidth=3)\n",
        "plt.xlabel('Number of Neighbors'); plt.ylabel('RMSE')\n",
        "plt.title(r'Evaluate KNN regressor RMSE with different number of neighbors')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "\n",
        "\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "# Plotting\n",
        "#plt.figure(figsize=(18, 8))\n",
        "plt.plot(n_neighbors, mae, 'bo-', label='MAE of testing set', color=\"darkblue\", alpha=0.6, linewidth=1)\n",
        "#plt.plot(val_r_squared, 'bo-', label=r'$R^2$ Val set', color=\"darkred\", alpha=0.6, linewidth=3)\n",
        "plt.xlabel('number of neighbors'); plt.ylabel('MAE')\n",
        "plt.title(r'Evaluate KNN regressor MAE with different number of neighbors')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "# Plotting\n",
        "#plt.figure(figsize=(18, 8))\n",
        "plt.plot(n_neighbors, yhat_mean, 'bo-', label='prediction of testing set', color=\"darkblue\", alpha=0.6, linewidth=1)\n",
        "plt.plot(n_neighbors, ytest_mean, 'bo-', label='true value of testing set', color=\"darkred\", alpha=0.6, linewidth=1)\n",
        "plt.xlabel('number of neighbors'); plt.ylabel('Price')\n",
        "plt.title(r'Evaluate kNN regressor Prices with different number of neighbors')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-w4Qk_TOaRWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## decision tree"
      ],
      "metadata": {
        "id": "SdWtBttQaV1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {\n",
        "    'max_depth': range (5, 20),\n",
        "    'min_samples_leaf': [5, 10, 15, 20, 25]}\n",
        "\n",
        "grid_search = GridSearchCV(DecisionTreeRegressor(), parameters, cv=10, return_train_score=False, scoring='neg_mean_squared_error', n_jobs=4)\n",
        "grid_search.fit(X_train, y_train)\n",
        "grid_results = pd.DataFrame(grid_search.cv_results_)\n",
        "grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "RywGMsgAaVMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mae = []\n",
        "rmse = []\n",
        "r2_mean = []\n",
        "yhat_mean = []\n",
        "ytest_mean = []\n",
        "r2 = []\n",
        "explained_var =[]\n",
        "cv_rmse = []\n",
        "model = DecisionTreeRegressor(max_depth=12, min_samples_leaf=15)\n",
        "model.fit(X_train, y_train)\n",
        "yhat = model.predict(X_test)\n",
        "y_hat_train = model.predict(X_train)\n",
        "r2.append(model.score(X_test, y_test))\n",
        "mae.append(mean_absolute_error(y_test, yhat))\n",
        "rmse.append(np.sqrt(mean_squared_error(y_test, yhat)))\n",
        "print('Root Mean Squared Error train:', np.sqrt(mean_squared_error(y_train, y_hat_train)))\n",
        "print('Mean Predicted Selling Price:', yhat.mean())\n",
        "print('Mean Selling Price:', y_test.mean())\n",
        "yhat_mean.append(yhat.mean())\n",
        "ytest_mean.append(y_test.mean())\n",
        "score = cross_val_score(model, X, y,cv=10, scoring=\"r2\")\n",
        "print('R_squared Mean Score:',score.mean())\n",
        "var = cross_val_score(model, X, y,cv=10, scoring=\"explained_variance\")\n",
        "print('explained var Mean Score:',var.mean())\n",
        "cv_rmse = cross_val_score(model, X, y,cv=10, scoring=\"neg_root_mean_squared_error\")\n",
        "print('RMSE Mean Score:',cv_rmse.mean())\n",
        "r2_mean.append(score.mean())\n",
        "print(score)\n",
        "print(var)"
      ],
      "metadata": {
        "id": "MGNPiiOraTKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_scores = grid_results.sort_values(by='rank_test_score')[['params', 'mean_test_score', 'std_test_score' ]]\n",
        "df_scores[['mean_test_score',  'std_test_score']] = np.sqrt(df_scores[['mean_test_score',  'std_test_score']].abs())\n",
        "df_scores.head()"
      ],
      "metadata": {
        "id": "BHS6gWHZacoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## random forest"
      ],
      "metadata": {
        "id": "OBFD3s1Iaguo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {\n",
        "    'max_depth': range (5, 20),\n",
        "    'n_estimators': [5, 10, 15, 20, 30]}\n",
        "\n",
        "grid_search = GridSearchCV(RandomForestRegressor(), parameters, cv=10, return_train_score=False, scoring='neg_mean_squared_error', n_jobs=4)\n",
        "grid_search.fit(X_train, y_train)\n",
        "grid_results = pd.DataFrame(grid_search.cv_results_)\n",
        "grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "9Bl-1S3Pae0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mae = []\n",
        "rmse = []\n",
        "r2_mean = []\n",
        "yhat_mean = []\n",
        "ytest_mean = []\n",
        "r2 = []\n",
        "model = RandomForestRegressor(max_depth=16,\n",
        "                              n_estimators=30)\n",
        "model.fit(X_train, y_train)\n",
        "yhat = model.predict(X_test)\n",
        "y_hat_train = model.predict(X_train)\n",
        "r2.append(model.score(X_test, y_test))\n",
        "mae.append(mean_absolute_error(y_test, yhat))\n",
        "rmse.append(np.sqrt(mean_squared_error(y_test, yhat)))\n",
        "print('Root Mean Squared Error train:', np.sqrt(mean_squared_error(y_train, y_hat_train)))\n",
        "print('Mean Predicted Selling Price:', yhat.mean())\n",
        "print('Mean Selling Price:', y_test.mean())\n",
        "yhat_mean.append(yhat.mean())\n",
        "ytest_mean.append(y_test.mean())\n",
        "score = cross_val_score(model, X, y,cv=10, scoring=\"r2\")\n",
        "print('R_squared Mean Score:',score.mean())\n",
        "var = cross_val_score(model, X, y,cv=10, scoring=\"explained_variance\")\n",
        "print('explained var Mean Score:',var.mean())\n",
        "cv_rmse = cross_val_score(model, X, y,cv=10, scoring=\"neg_root_mean_squared_error\")\n",
        "print('RMSE Mean Score:',cv_rmse.mean())\n",
        "r2_mean.append(score.mean())\n",
        "print(score)\n"
      ],
      "metadata": {
        "id": "ZMHkueB7aihB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGB"
      ],
      "metadata": {
        "id": "jZFLKBQDak_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "param={\n",
        "    'objective': 'reg:linear',\n",
        "    'eta'      :0.02,\n",
        "    'eval_metric':'rmse',\n",
        "    'max_depth': 5,\n",
        "    'min_child_weight':3,\n",
        "    'subsample' : 0.8,\n",
        "    'colsample_bytree' : 0.8,\n",
        "    'silent': 1,\n",
        "    'seed' : 123\n",
        "}\n",
        "trn = xgb.DMatrix(X_train,label=y_train)\n",
        "tst = xgb.DMatrix(X_test,label=y_test)\n",
        "res = xgb.cv(param,trn,nfold=4,num_boost_round=2000,early_stopping_rounds=50,\n",
        "            show_stdv=True,metrics={'rmse'},maximize=False)\n",
        "min_index=np.argmin(res['test-rmse-mean'])\n",
        "\n",
        "model = xgb.train(param,trn,min_index,[(trn,'train'),(tst,'test')])\n",
        "pred = model.predict(tst)\n",
        "print('Test RMSE:', np.sqrt(mean_squared_error(y_test,pred)))"
      ],
      "metadata": {
        "id": "C3tB4bW0akPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_sq = ((pred-np.mean(y_test))**2).sum() / ((y_test - np.mean(y_test))**2).sum()\n",
        "print('R square is: ', r_sq)"
      ],
      "metadata": {
        "id": "R7rFsD8Zan3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Personal pipeline"
      ],
      "metadata": {
        "id": "GKcjdoq3ar1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipelines = []\n",
        "seed = 2\n",
        "\n",
        "pipelines.append(\n",
        "                (\"Scaled_Ridge\", \n",
        "                 Pipeline([\n",
        "                     (\"Scaler\", StandardScaler()), \n",
        "                     (\"Ridge\", Ridge(random_state=seed, alpha=0.01 ))\n",
        "                      ]))\n",
        "                )\n",
        "pipelines.append(\n",
        "                (\"Scaled_Lasso\", \n",
        "                 Pipeline([\n",
        "                     (\"Scaler\", StandardScaler()), \n",
        "                     (\"Lasso\", Lasso(random_state=seed, tol=1))\n",
        "                      ]))\n",
        "                )\n",
        "pipelines.append(\n",
        "                (\"Scaled_Elastic\", \n",
        "                 Pipeline([\n",
        "                     (\"Scaler\", StandardScaler()), \n",
        "                     (\"Lasso\", ElasticNet(random_state=seed))\n",
        "                      ]))\n",
        "                )\n",
        "\n",
        "\n",
        "pipelines.append(\n",
        "                (\"Scaled_RF_reg\",\n",
        "                 Pipeline([\n",
        "                     (\"Scaler\", StandardScaler()),\n",
        "                     (\"RF\", RandomForestRegressor(max_depth=16, n_estimators=30,random_state = seed))\n",
        "                 ])\n",
        "                )\n",
        "                )\n",
        "\n",
        "pipelines.append(\n",
        "                (\"Scaled_ET_reg\",\n",
        "                 Pipeline([\n",
        "                     (\"Scaler\", StandardScaler()),\n",
        "                     (\"ET\", ExtraTreesRegressor(random_state=seed))\n",
        "                 ])\n",
        "                )\n",
        "                )\n",
        "pipelines.append(\n",
        "                (\"Scaled_BR_reg\",\n",
        "                 Pipeline([\n",
        "                     (\"Scaler\", StandardScaler()),\n",
        "                     (\"BR\", BaggingRegressor(random_state=seed))\n",
        "                 ]))) \n",
        "\n",
        "pipelines.append(\n",
        "                (\"Scaled_Hub-Reg\",\n",
        "                 Pipeline([\n",
        "                     (\"Scaler\", StandardScaler()),\n",
        "                     (\"Hub-Reg\", HuberRegressor())\n",
        "                 ]))) \n",
        "pipelines.append(\n",
        "                (\"Scaled_BayRidge\",\n",
        "                 Pipeline([\n",
        "                     (\"Scaler\", StandardScaler()),\n",
        "                     (\"BR\", BayesianRidge())\n",
        "                 ]))) \n",
        "\n",
        "pipelines.append(\n",
        "                (\"Scaled_XGB_reg\",\n",
        "                 Pipeline([\n",
        "                     (\"Scaler\", StandardScaler()),\n",
        "                     (\"XGBR\", XGBRegressor( ))])))\n",
        "pipelines.append(\n",
        "                (\"Scaled_DT_reg\",\n",
        "                 Pipeline([\n",
        "                     (\"Scaler\", StandardScaler()),\n",
        "                     (\"DT_reg\", DecisionTreeRegressor(max_depth = 12, min_samples_leaf = 15))\n",
        "                 ]))) \n",
        "\n",
        "pipelines.append(\n",
        "                (\"Scaled_KNN_reg\",\n",
        "                 Pipeline([\n",
        "                     (\"Scaler\", StandardScaler()),\n",
        "                     (\"KNN_reg\", KNeighborsRegressor())\n",
        "                 ])))\n",
        "pipelines.append(\n",
        "                (\"Scaled_ADA-Reg\",\n",
        "                 Pipeline([\n",
        "                     (\"Scaler\", StandardScaler()),\n",
        "                     (\"ADA-reg\", AdaBoostRegressor())\n",
        "                 ]))) \n",
        "\n",
        "pipelines.append(\n",
        "                (\"Scaled_Gboost-Reg\",\n",
        "                 Pipeline([\n",
        "                     (\"Scaler\", StandardScaler()),\n",
        "                     (\"GBoost-Reg\", GradientBoostingRegressor())\n",
        "                 ])))\n",
        "\n",
        "pipelines.append(\n",
        "                (\"Scaled_RFR_PCA\",\n",
        "                 Pipeline([\n",
        "                     (\"Scaler\", StandardScaler()),\n",
        "                     (\"PCA\", PCA(n_components=3)),\n",
        "                     (\"XGB\", RandomForestRegressor())\n",
        "                 ])))\n",
        "\n",
        "pipelines.append(\n",
        "                (\"Scaled_XGBR_PCA\",\n",
        "                 Pipeline([\n",
        "                     (\"Scaler\", StandardScaler()),\n",
        "                     (\"PCA\", PCA(n_components=3)),\n",
        "                     (\"XGB\", XGBRegressor())\n",
        "                 ])))\n",
        "\n",
        "#'neg_mean_absolute_error', 'neg_mean_squared_error','r2'\n",
        "scoring = 'r2'\n",
        "n_folds = 10\n",
        "\n",
        "results, names  = [], [] \n",
        "var, rmse = [],[]\n",
        "\n",
        "for name, model  in pipelines:\n",
        "    kfold = KFold(n_splits=n_folds)\n",
        "    cv_results = cross_val_score(model, X, y, cv= kfold,\n",
        "                                 scoring=scoring, n_jobs=-1) \n",
        "    cv_r = cross_val_score(model, X, y, cv= kfold,\n",
        "                                 scoring='explained_variance', n_jobs=-1) \n",
        "    cv_rmse =   cross_val_score(model, X, y, cv= kfold,\n",
        "                                 scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
        "    names.append(name)\n",
        "    results.append(cv_results)    \n",
        "    msg = \"%s: %f (+/- %f)\" % (name, cv_results.mean(),  cv_results.std())\n",
        "    print(msg)\n",
        "    var.append(cv_r)\n",
        "    msg_2 = \"%s: %f (+/- %f)\" % (name, cv_r.mean(),  cv_r.std())\n",
        "    print(msg_2)\n",
        "    rmse.append(cv_rmse)\n",
        "    msg_3 = \"%s: %f (+/- %f)\" % (name, cv_rmse.mean(),  cv_rmse.std())\n",
        "    print(msg_3)"
      ],
      "metadata": {
        "id": "qxeinSYAaxED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# boxplot algorithm comparison\n",
        "fig = plt.figure(figsize=(15,6))\n",
        "fig.suptitle('Algorithm Comparison', fontsize=22)\n",
        "ax = fig.add_subplot(111)\n",
        "rm = [ -x for x in rmse]\n",
        "pyplot.boxplot(rm, labels=names, showmeans=True)\n",
        "ax.set_xticklabels(names)\n",
        "ax.set_xlabel(\"Algorithmn Name\", fontsize=20)\n",
        "ax.set_ylabel(\"RMSE Score of Models\", fontsize=18)\n",
        "ax.set_xticklabels(ax.get_xticklabels(),rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ClLU8sbMaz5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(15,6))\n",
        "fig.suptitle('Algorithm Comparison', fontsize=22)\n",
        "ax = fig.add_subplot(111)\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)\n",
        "ax.set_xticklabels(names)\n",
        "ax.set_xlabel(\"Algorithmn Name\", fontsize=20)\n",
        "ax.set_ylabel(\"R squared Score of Models\", fontsize=18)\n",
        "ax.set_xticklabels(ax.get_xticklabels(),rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fdz5gOQKa1d-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(15,6))\n",
        "fig.suptitle('Algorithm Comparison', fontsize=22)\n",
        "ax = fig.add_subplot(111)\n",
        "pyplot.boxplot(var, labels=names, showmeans=True)\n",
        "ax.set_xticklabels(names)\n",
        "ax.set_xlabel(\"Algorithmn Name\", fontsize=20)\n",
        "ax.set_ylabel(\"R squared Score of Models\", fontsize=18)\n",
        "ax.set_xticklabels(ax.get_xticklabels(),rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iw6no45Ea4F6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DNN"
      ],
      "metadata": {
        "id": "iunvkQsjbx5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['log_price'] = np.log(df['price'])"
      ],
      "metadata": {
        "id": "j2uss-7Ub6AE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df =df.drop(columns=[\"price\"])"
      ],
      "metadata": {
        "id": "HDpyAWrxb8KI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = df.sample(frac=0.8,random_state=0)\n",
        "test_dataset = df.drop(train_dataset.index)"
      ],
      "metadata": {
        "id": "CFY8cF4Ha4fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_stats = train_dataset.describe()\n",
        "train_stats.pop('log_price')\n",
        "train_stats = train_stats.transpose()\n",
        "train_stats"
      ],
      "metadata": {
        "id": "LRlbBkGBb3wv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = train_dataset.pop('log_price')\n",
        "test_labels = test_dataset.pop('log_price')"
      ],
      "metadata": {
        "id": "3h1fM_bfb9nC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def norm(x):\n",
        "  return (x - train_stats['mean']) / train_stats['std']\n",
        "normed_train_data = norm(train_dataset)\n",
        "normed_test_data = norm(test_dataset)"
      ],
      "metadata": {
        "id": "4kQ1PFh0b_yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normed_train_data.shape"
      ],
      "metadata": {
        "id": "xnGMlpA2cA2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "  model = keras.Sequential([\n",
        "    layers.Dense(21, activation='relu', input_shape=[len(train_dataset.keys())]),\n",
        "    layers.Dense(21, activation='relu'),\n",
        "    layers.Dense(21, activation='relu'),\n",
        "    layers.Dense(1),\n",
        "  ])\n",
        "\n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "  model.compile(loss='mse',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae', 'mse'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "VwE-REX-cCBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()"
      ],
      "metadata": {
        "id": "s1tYThIzcDSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PrintDot(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    if epoch % 100 == 0: print('')\n",
        "    print('.', end='')\n",
        "\n",
        "EPOCHS = 1000\n",
        "\n",
        "history = model.fit(\n",
        "  normed_train_data, train_labels,\n",
        "  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
        "  callbacks=[PrintDot()])"
      ],
      "metadata": {
        "id": "pe05BmPqcE1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions=model.predict(normed_test_data)\n",
        "print(\"The Variance Score :\", explained_variance_score(test_labels, predictions))"
      ],
      "metadata": {
        "id": "VHOfnTyScGiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_absolute_error(test_labels,predictions)"
      ],
      "metadata": {
        "id": "odqBmVYbcHz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_squared_error(test_labels,predictions)**0.5"
      ],
      "metadata": {
        "id": "Q4uz40Y4cJB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "  model = keras.Sequential([\n",
        "    layers.Dense(21, activation='relu', input_shape=[len(train_dataset.keys())]),\n",
        "    layers.Dense(21, activation='relu'),\n",
        "    layers.Dense(21, activation='relu'),\n",
        "    layers.Dense(1),\n",
        "  ])\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "  model.compile(loss='mse',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae', 'mse'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "BL0P5raVcKiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()"
      ],
      "metadata": {
        "id": "RaIRNV1KcMST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PrintDot(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    if epoch % 100 == 0: print('')\n",
        "    print('.', end='')\n",
        "\n",
        "EPOCHS = 1000\n",
        "\n",
        "history = model.fit(\n",
        "  normed_train_data, train_labels,\n",
        "  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
        "  callbacks=[PrintDot()])"
      ],
      "metadata": {
        "id": "hM_9qSJbcNhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions=model.predict(normed_test_data)\n",
        "print(\"The Variance Score :\", explained_variance_score(test_labels, predictions))"
      ],
      "metadata": {
        "id": "2HGdX8hJcP3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_absolute_error(test_labels,predictions)"
      ],
      "metadata": {
        "id": "JgVEyFD3cRT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_squared_error(test_labels,predictions)**0.5"
      ],
      "metadata": {
        "id": "PQXN28mCcTwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "reference\n",
        "\n",
        "data source:\n",
        "https://www.kaggle.com/datasets/harlfoxem/housesalesprediction\n",
        "\n",
        "https://www.kaggle.com/code/dktalaicha/house-price-prediction-with-keras#Evaluation-on-Test-Data\n",
        "\n",
        "https://www.kaggle.com/code/arthurtok/feature-ranking-rfe-random-forest-linear-models\n",
        "\n",
        "https://www.kaggle.com/code/vivianbenben/exploration-and-xgboost-to-predict-housing-price\n",
        "\n",
        "https://www.kaggle.com/code/kabure/predicting-house-prices-xgb-rf-bagging-reg-pipe"
      ],
      "metadata": {
        "id": "Zk09aLS4fCIq"
      }
    }
  ]
}